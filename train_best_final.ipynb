{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "6cfee2bad94d2a199856bba715a6a719a1b6dadbcd1d366ba7b99cf78a59f189"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yun-K/COMP261_a5_stringSearch_and_2compressionAlgorithms/blob/main/train_best_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tchHTYls7AkS"
      },
      "source": [
        "# Name: Yun Zhou\n",
        "# ID:   300442776\n",
        "#  # for using the vs code on colab\n",
        "#  !pip install colabcode\n",
        "# from colabcode import ColabCode\n",
        "# ColabCode(port=10000,password=\"12345\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY7K-k8W7bJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e60058-0821-4098-c22b-e7848eee1847"
      },
      "source": [
        "!pip install torchmetrics"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.5.1-py3-none-any.whl (282 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 282 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.9.0+cu111)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (2.4.7)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IirwIFv57AkV"
      },
      "source": [
        "import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov9Ejz8F7AkY"
      },
      "source": [
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "# import helper\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch  # PyTorch\n",
        "import torch.autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchmetrics  # metrics like accuracy, recall, etc\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms  # for image Transformation\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.metrics import (accuracy_score, confusion_matrix, make_scorer,\n",
        "                             mean_absolute_error, mean_squared_error,\n",
        "                             precision_recall_fscore_support, recall_score,\n",
        "                             roc_auc_score)\n",
        "from sklearn.model_selection import (KFold, LeaveOneOut, ShuffleSplit,\n",
        "                                     cross_val_score, cross_validate,\n",
        "                                     train_test_split)\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.modules.container import Sequential\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.optim.lr_scheduler import (CosineAnnealingLR, ReduceLROnPlateau,\n",
        "                                      StepLR)\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split\n",
        "from torch.utils.data.sampler import SubsetRandomSampler  # Sampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# import myutil\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW08HzYS7AkZ"
      },
      "source": [
        "initialize some necessary global variable\n",
        "And set up google colab path \n",
        "> https://medium.com/analytics-vidhya/how-to-use-google-colab-with-github-via-google-drive-68efb23a42d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-JSWHy07Aka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b02134b-c863-495d-cb83-4aaf06d511e8"
      },
      "source": [
        "# for using CPU or GPU\n",
        "# import torch \n",
        "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"we can use:\", DEVICE, \"to run the Model \")\n",
        "\n",
        "isColab = True  if torch.cuda.is_available() else False\n",
        "# isColab = !isColab #for CPU on colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "if isColab:\n",
        "  print(\"Use google drive\")\n",
        "  # !cd /content/gdrive/MyDrive/ && ls\n",
        "\n",
        "PREFIX_PATH = \"/content/gdrive/MyDrive/\"\n",
        "DATA_PATH = \"/content/gdrive/MyDrive/traindata\" if isColab else \"../traindata\"\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we can use: cuda to run the Model \n",
            "Mounted at /content/gdrive\n",
            "Use google drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG7D8PLB7Akb"
      },
      "source": [
        "load, preprocess and construct the dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nDDUX5j7Akc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3380ebda-900e-4491-ae7d-713a2f82ce8f"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "train_size_coef = 0.8\n",
        "RANDOM_SEED = 309\n",
        "\n",
        "def load_preprocess_construct_data(path=DATA_PATH,BATCH_SIZE = BATCH_SIZE):\n",
        "    dataset_whole = ImageFolder(path, transform=transforms.Compose(\n",
        "        [\n",
        "            # scale each images into the same size\n",
        "            transforms.Resize((300, 300)),\n",
        "            transforms.ToTensor(),  # transform them into tensor\n",
        "\n",
        "            # normalize tensor images with mean and std\n",
        "            # which means all channel of the input tensor images will be normalized\n",
        "            transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
        "                                 std=(0.5, 0.5, 0.5), inplace=False),\n",
        "            transforms.RandomRotation(degrees=(0, 180))\n",
        "        ])\n",
        "    )\n",
        "    print(\"whole set len:\", len(dataset_whole))\n",
        "    # split the data into train/valid set\n",
        "    train_set, valid_set = train_test_split(dataset_whole, train_size=train_size_coef,\n",
        "                                            random_state=RANDOM_SEED)\n",
        "    # shuffle:TRUE means random sample\n",
        "    # drop_last:False will make sure that no images will be droped even there are no enough BATCH_SIZE(e.g. 64) images at the last round\n",
        "    train_loader = DataLoader(\n",
        "        train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=False)\n",
        "    valid_loader = DataLoader(\n",
        "        valid_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=False)\n",
        "\n",
        "    print(dataset_whole.classes)\n",
        "\n",
        "    print(\"whole set len:\", len(dataset_whole))\n",
        "    print(\"train set len:\", len(train_set))\n",
        "    print(\"valid set len:\", len(valid_set))\n",
        "    print(\"train+valid set len:\", len(train_set)+len(valid_set))\n",
        "\n",
        "    return dataset_whole, train_set, valid_set, train_loader, valid_loader\n",
        "\n",
        "\n",
        "dataset_whole, train_set, valid_set, train_loader, valid_loader = load_preprocess_construct_data()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "whole set len: 5026\n",
            "['cherry', 'strawberry', 'tomato']\n",
            "whole set len: 5026\n",
            "train set len: 4020\n",
            "valid set len: 1006\n",
            "train+valid set len: 5026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmEQscCv7Akd"
      },
      "source": [
        " use the tensorboard for visualize the data more convenient\n",
        " \n",
        " ``` \n",
        "tensorboard --logdir=preprocess\n",
        " ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAwu3B7H7Akd"
      },
      "source": [
        "# preprocess_path  = \"/content/gdrive/MyDrive/Colab_Notebooks/preprocess\" if isColab else \"preprocess\"\n",
        "# writer = SummaryWriter(preprocess_path)\n",
        "# preprocess_step = 0\n",
        "# for (image_X,target_Y) in train_loader:\n",
        "#     # imgtensor=y-axis, global step = x axis\n",
        "#     writer.add_images(tag=\"data\", img_tensor=image_X, global_step=preprocess_step)\n",
        "#     preprocess_step = preprocess_step + 1\n",
        "# writer.close()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP8zhgFx7Ake"
      },
      "source": [
        "get the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtuzanW18k95"
      },
      "source": [
        "# # https://www.kaggle.com/artgor/simple-eda-and-model-in-pytorch/notebook\n",
        "# # https://www.mashen.zone/thread-1825047.htm\n",
        "# # https://blog.csdn.net/nanke_4869/article/details/113458729\n",
        "# # CNN model\n",
        "# class CNN(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Sequential(            \n",
        "#             nn.Conv2d(\n",
        "#               in_channels=3,# Number of channels in the input image:input height,mark the amount of color channels,it is 3 since RGB is 3 channel\n",
        "#               out_channels=64,#n_filter, Number of channels produced by the convolution\n",
        "#               kernel_size=3,#filter size\n",
        "#               stride=1,#filter step, Stride of the convolution\n",
        "#               padding=1# controls the amount of padding applied to the inpu\n",
        "#             ),\n",
        "#             # Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\n",
        "#             nn.BatchNorm2d(32),\n",
        "                        \n",
        "#             nn.Conv2d(\n",
        "#               in_channels=64,# Number of channels in the input image:input height,mark the amount of color channels\n",
        "#               out_channels=64,#n_filter, Number of channels produced by the convolution\n",
        "#               kernel_size=3,#filter size\n",
        "#               stride=1,#filter step, Stride of the convolution\n",
        "#               padding=1# controls the amount of padding applied to the inpu\n",
        "#             ),\n",
        "#             # activation function\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             # https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
        "#             # pooling\n",
        "#             nn.MaxPool2d(2),\n",
        "            \n",
        "#             # use dropout to enable a kind of early stop which can avoid the over-fit \n",
        "#             nn.Dropout(0.3)    \n",
        "#         )\n",
        "#         self.conv2 = nn.Sequential(\n",
        "#             nn.Conv2d(\n",
        "#               in_channels=64,# Number of channels in the input image:input height,mark the amount of color channels\n",
        "#               out_channels=128,#n_filter, Number of channels produced by the convolution\n",
        "#               kernel_size=3,#filter size\n",
        "#               stride=1,#filter step, Stride of the convolution\n",
        "#               padding=1# controls the amount of padding applied to the inpu\n",
        "#             ),\n",
        "#             nn.Conv2d(\n",
        "#               in_channels=128,# Number of channels in the input image:input height,mark the amount of color channels\n",
        "#               out_channels=128,#n_filter, Number of channels produced by the convolution\n",
        "#               kernel_size=3,#filter size\n",
        "#               stride=1,#filter step, Stride of the convolution\n",
        "#               padding=1# controls the amount of padding applied to the inpu\n",
        "#             ),\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             # pooling\n",
        "#             nn.MaxPool2d(2),\n",
        "#             # use dropout to enable a kind of early stop which can avoid the over-fit \n",
        "#             nn.Dropout(0.3)\n",
        "#         )\n",
        "#         self.conv3 = nn.Sequential(\n",
        "#             nn.Conv2d(\n",
        "#               in_channels=128,# Number of channels in the input image:input height,mark the amount of color channels\n",
        "#               out_channels=256,#n_filter, Number of channels produced by the convolution\n",
        "#               kernel_size=3,#filter size\n",
        "#               stride=1,#filter step, Stride of the convolution\n",
        "#               padding=1# controls the amount of padding applied to the inpu\n",
        "#             ),\n",
        "#             nn.Conv2d(\n",
        "#               in_channels=256,# Number of channels in the input image:input height,mark the amount of color channels\n",
        "#               out_channels=256,#n_filter, Number of channels produced by the convolution\n",
        "#               kernel_size=3,#filter size\n",
        "#               stride=1,#filter step, Stride of the convolution\n",
        "#               padding=1# controls the amount of padding applied to the inpu\n",
        "#             ),\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             nn.MaxPool2d(2),\n",
        "#             # use dropout to enable a kind of early stop which can avoid the over-fit \n",
        "#             nn.Dropout(0.3)\n",
        "#         )\n",
        "#         self.conv4 = nn.Sequential(\n",
        "#             nn.Conv2d(\n",
        "#               in_channels=256,# Number of channels in the input image:input height,mark the amount of color channels\n",
        "#               out_channels=512,#n_filter, Number of channels produced by the convolution\n",
        "#               kernel_size=3,#filter size\n",
        "#               stride=1,#filter step, Stride of the convolution\n",
        "#               padding=1# controls the amount of padding applied to the inpu\n",
        "#             ),\n",
        "#             nn.Conv2d(\n",
        "#               in_channels=512,# Number of channels in the input image:input height,mark the amount of color channels\n",
        "#               out_channels=512,#n_filter, Number of channels produced by the convolution\n",
        "#               kernel_size=3,#filter size\n",
        "#               stride=1,#filter step, Stride of the convolution\n",
        "#               padding=1# controls the amount of padding applied to the inpu\n",
        "#             ),\n",
        "#             nn.ReLU(inplace = True),\n",
        "#             nn.MaxPool2d(2),\n",
        "#             # use dropout to enable a kind of early stop which can avoid the over-fit \n",
        "#             nn.Dropout(0.3)\n",
        "#         )\n",
        "\n",
        "#         self.flatten = nn.Flatten()\n",
        "#         self.fc1 = nn.Sequential(\n",
        "#             nn.Linear(512*18*18,512),\n",
        "#             # use dropout to enable a kind of early stop which can avoid the over-fit \n",
        "#             nn.Dropout(0.3),\n",
        "#         )\n",
        "#         self.fc2 = nn.Sequential(\n",
        "#             nn.Linear(512,3)\n",
        "#         )\n",
        "        \n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.conv2(x)\n",
        "#         x = self.conv3(x)\n",
        "#         x = self.conv4(x)\n",
        "#         x = self.flatten(x)\n",
        "#         x = self.fc1(x)\n",
        "#         x = self.fc2(x)\n",
        "#         return x\n",
        "\n",
        "#     def to_model_string(self):\n",
        "#         return 'CNN'\n",
        "\n",
        "\n",
        "\n",
        "# something has to be commented out since no enough GPU memory in Colab\n",
        "class CNN(nn.Module):\n",
        "  \"\"\"\n",
        "https://datascience.stackexchange.com/questions/40906/determining-size-of-fc-layer-after-conv-layer-in-pytorch\n",
        "  https://towardsdatascience.com/classification-of-fruit-images-using-neural-networks-pytorch-1d34d49342c7\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      self.network = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=3, out_channels= 32, kernel_size=3, stride=1, padding=1), #3 channels to 32 channels\n",
        "          # Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.ReLU(inplace = True), # activitation function \n",
        "          nn.MaxPool2d(2, 2), # output: 32 channels x 150 x 150 image size - decrease\n",
        "          nn.Dropout(0.25), \n",
        "\n",
        "          nn.Conv2d(in_channels=32, out_channels= 64, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ReLU(inplace = True), # activitation function \n",
        "          nn.MaxPool2d(2, 2), # output: 64 x 75 x 75\n",
        "          # use dropout to enable a kind of early stop which can avoid the over-fit \n",
        "          nn.Dropout(0.25), \n",
        "\n",
        "          nn.Conv2d(in_channels=64, out_channels= 128, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.ReLU(inplace = True), # activitation function \n",
        "          nn.Conv2d(in_channels=128, out_channels= 128, kernel_size=3, stride=1, padding=1), #can keep the same, increase power of model , go deeper as u add linearity to non-linearity\n",
        "          # nn.BatchNorm2d(128),\n",
        "          nn.ReLU(inplace = True), # activitation function \n",
        "          nn.MaxPool2d(3, 3), # output: 128 x 25 x 25\n",
        "          # use dropout to enable a kind of early stop which can avoid the over-fit \n",
        "          nn.Dropout(0.25), \n",
        "\n",
        "          nn.Conv2d(in_channels=128, out_channels= 256, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(256),\n",
        "          nn.ReLU(inplace = True), # activitation function \n",
        "          nn.Conv2d(in_channels=256, out_channels= 256, kernel_size=3, stride=1, padding=1),\n",
        "          nn.ReLU(inplace = True), # activitation function \n",
        "          nn.Dropout(0.25), \n",
        "          \n",
        "          nn.Conv2d(in_channels=256, out_channels= 512, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(512),\n",
        "          # nn.MaxPool2d(2),\n",
        "          nn.ReLU(inplace = True), # activitation function \n",
        "          # nn.Conv2d(in_channels=256, out_channels= 256, kernel_size=3, stride=1, padding=1),\n",
        "          # nn.BatchNorm2d(512),\n",
        "          # nn.MaxPool2d(2),\n",
        "          # nn.ReLU(inplace = True), # activitation function \n",
        "          nn.MaxPool2d(5, 5), # output: 512 x 5 x 5\n",
        "          # use dropout to enable a kind of early stop which can avoid the over-fit \n",
        "          nn.Dropout(0.25), \n",
        "\n",
        "          # nn.Conv2d(in_channels=256, out_channels= 512, kernel_size=3, stride=1, padding=1),\n",
        "          # nn.BatchNorm2d(512),\n",
        "          # nn.ReLU(inplace = True), # activitation function \n",
        "          # # nn.Conv2d(in_channels=512, out_channels= 512, kernel_size=3, stride=1, padding=1),\n",
        "          # nn.BatchNorm2d(512),\n",
        "          # # nn.MaxPool2d(2),\n",
        "          # nn.ReLU(inplace = True), # activitation function \n",
        "          # nn.MaxPool2d(5, 5), # output: 512 x 5 x 5\n",
        "          # # use dropout to enable a kind of early stop which can avoid the over-fit \n",
        "          # nn.Dropout(0.25), \n",
        "\n",
        "          nn.Flatten(), #a single vector 512*5*5,\n",
        "          nn.Linear(512*5*5, 512),\n",
        "          nn.ReLU(inplace = True), # activitation function \n",
        "          nn.Dropout(0.25), \n",
        "\n",
        "          # nn.ReLU(inplace = True), # activitation function \n",
        "          # nn.Linear(1024, 512),\n",
        "          # nn.ReLU(),\n",
        "          nn.Linear(512, 3)\n",
        "          \n",
        "\n",
        "          # nn.Dropout(0.25), \n",
        "          # 512,131 on towardsDatascience, dont know what it is , \n",
        "          # I think it might be the batch_size(128) + classes(3)?\n",
        "          # need to test performances\n",
        "          # nn.Linear(512, 131) \n",
        "          \n",
        "          )\n",
        "      \n",
        "  def forward(self, xb):\n",
        "      return self.network(xb)\n",
        "\n",
        "\n",
        "  def to_model_string(self):\n",
        "      return 'CNN'\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvswpbTf7Ake",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f773cbbe-8308-4031-9b9f-7b3fe52fea9b"
      },
      "source": [
        "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"we can use:\", DEVICE, \"to run the Model \")\n",
        "model = CNN().to(DEVICE) #enable the GPU trian if we can \n",
        "print(\"Our model: \")\n",
        "print(model)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we can use: cuda to run the Model \n",
            "Our model: \n",
            "CNN(\n",
            "  (network): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Dropout(p=0.25, inplace=False)\n",
            "    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (9): Dropout(p=0.25, inplace=False)\n",
            "    (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): ReLU(inplace=True)\n",
            "    (15): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "    (16): Dropout(p=0.25, inplace=False)\n",
            "    (17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): ReLU(inplace=True)\n",
            "    (22): Dropout(p=0.25, inplace=False)\n",
            "    (23): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
            "    (27): Dropout(p=0.25, inplace=False)\n",
            "    (28): Flatten(start_dim=1, end_dim=-1)\n",
            "    (29): Linear(in_features=12800, out_features=512, bias=True)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): Dropout(p=0.25, inplace=False)\n",
            "    (32): Linear(in_features=512, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMgLbDjY7Akf"
      },
      "source": [
        "performance metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7gw9XA97Akf"
      },
      "source": [
        "def get_accuracy(net, testloader):\n",
        "    \"\"\"\n",
        "    NOT USED in my CODE\n",
        "    this code snipest is from:\n",
        "    https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "    \"\"\"\n",
        "    correct, total = 0, 0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = net(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total  # * 100"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac9ffsbvIxQC"
      },
      "source": [
        "for adjusting lr based on epoches, which is about scheduler\n",
        "> https://pytorch.org/docs/stable/optim.html\n",
        "> https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html\n",
        "> `https://zhuanlan.zhihu.com/p/261134624`\n",
        "\n",
        ">https://stackoverflow.com/questions/65343377/adam-optimizer-with-warmup-on-pytorch\n",
        "\n",
        ">`https://www.reddit.com/r/MachineLearning/comments/oy3co1/d_how_to_pick_a_learning_rate_scheduler/`\n",
        ">`https://www.jeremyjordan.me/nn-learning-rate/`\n",
        ">\n",
        ">https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html\n",
        ">\n",
        ">\n",
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "417dxrgX7Akg"
      },
      "source": [
        "\n",
        "# initialize the torch metric  of accuracy\n",
        "train_accuracy = torchmetrics.Accuracy().to(DEVICE)\n",
        "valid_accuracy = torchmetrics.Accuracy().to(DEVICE)\n",
        "# torchmetrics.Precision().to(DEVICE) #dont count other metrics since it is time consuming \n",
        "\n",
        "loss_function = nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "LEARNING_RATE, MOMENTUM = 0.0001, 0.9\n",
        "# A Method for Stochastic Optimization_. The implementation of the L2 penalty follows changes proposed in Decoupled Weight Decay Regularization_.\n",
        "optimizer = optim.Adam(model.parameters() ,lr=LEARNING_RATE) # lr=0.001 is default lr for Adam, set to higher since we use scheduler\n",
        "\n",
        "# \n",
        "# optimizer = optim.RMSprop(model.parameters(),lr=LEARNING_RATE, momentum=MOMENTUM)\n",
        "# optimizer = optim.SGD(model.parameters(),lr=LEARNING_RATE, momentum=MOMENTUM)\n",
        "\n",
        "# optimizer = optim.SGD(model.parameters(),lr=LEARNING_RATE, momentum=MOMENTUM)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.99)\n",
        "\n",
        "# scheduler = CyclicLR(optimizer, base_lr=lr, max_lr=0.01, step_size=5, mode='triangular2')\n",
        "# scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "# scheduler = lr_scheduler.CosineAnnealingLR(optimizer)\n",
        "\n",
        "# scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=5,T_mult=2)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaaGjFXG7Akg"
      },
      "source": [
        "train the model several epoches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUpAhBUo7Akg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ddab85-fbec-42c4-f505-68b1c60468e5"
      },
      "source": [
        "# assert False\n",
        "model = model.train()\n",
        "total_step, valid_loss_min, valid_acc_best = 0, np.Inf, np.Inf\n",
        "loss_train_list, loss_val_list, acc_train_list, acc_valid_list, cur_lr_list = [], [], [], [], []\n",
        "\n",
        "best_model = {} # for storing the best mode based on the lowest loss \n",
        "p = 0  # epoch numers of the validation set loss didn't decrease\n",
        "stop = False  # whether stop the training process\n",
        "\n",
        "iters = len(train_loader)\n",
        "epoch_num = 75 if model.to_model_string()=='CNN' else 15\n",
        "print('total epoch num',epoch_num)\n",
        "for epoch in range(0, epoch_num):\n",
        "    if stop:\n",
        "        break\n",
        "        \n",
        "    # reset for current epoch\n",
        "    train_accuracy.reset()\n",
        "    valid_accuracy.reset()\n",
        "\n",
        "    train_loss = []\n",
        "\n",
        "    for batch_index, (image_X, target_Y) in enumerate(train_loader):\n",
        "        total_step = total_step+1\n",
        "        # enable the GPU train if we can\n",
        "        image_X, target_Y = image_X.to(DEVICE), target_Y.to(DEVICE)\n",
        "\n",
        "        # Sets the gradients of all optimized torch.Tensor s to zero.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # do the forward , back-propagation, and optimize\n",
        "        outputs = model(image_X)\n",
        "        loss = loss_function(outputs, target_Y)\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "        # store the accuracy\n",
        "        preds = torch.max(outputs, 1)[1]\n",
        "        train_accuracy(preds, target_Y)  # TODO:\n",
        "\n",
        "        # BACKWARD and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # #If call scheduler.step() after the end of an epoch,(i.e.outside this for loop)\n",
        "        # #Then all batches in an epoch use the same learning rate,\n",
        "        # #in order to make different batches use different learning rates\n",
        "        # #we call it in there\n",
        "        # scheduler.step(epoch + batch_index / iters)\n",
        "        # cur_lr=optimizer.param_groups[-1]['lr']\n",
        "        # cur_lr_list.append(cur_lr)\n",
        "        ## print('cur_lr:',cur_lr)\n",
        "    # print('epoch_{}_end'.format(epoch))\n",
        "\n",
        "    # scheduler.step(epoch) \n",
        "    cur_lr=optimizer.param_groups[-1]['lr']\n",
        "    cur_lr_list.append(cur_lr)\n",
        "\n",
        "    final_train_acc = train_accuracy.compute().item()  # * 100\n",
        "    acc_train_list.append(final_train_acc)\n",
        "    # FIXME: DIFF ???  use np.mean() or need to divide by len(trainset)\n",
        "    final_train_loss_mean = np.sum(train_loss)/len(train_set)\n",
        "    loss_train_list.append(final_train_loss_mean)\n",
        "\n",
        "    # for validation set\n",
        "    model.eval()\n",
        "    val_loss = []\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for batch_index, (image_X, target_Y) in enumerate(valid_loader):\n",
        "            # enable the GPU  if we can\n",
        "            image_X, target_Y = image_X.to(DEVICE), target_Y.to(DEVICE)\n",
        "            outputs = model(image_X)\n",
        "            loss = loss_function(outputs, target_Y)\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "            # store the accuracy\n",
        "            preds = torch.max(outputs, 1)[1]\n",
        "            valid_accuracy(preds, target_Y)  # TODO:\n",
        "    final_valid_acc = valid_accuracy.compute().item()  # * 100\n",
        "    acc_valid_list.append(final_valid_acc)\n",
        "\n",
        "    # FIXME: DIFF ???  use np.mean() or need to divide by len(trainset)\n",
        "    final_valid_loss_mean = np.sum(val_loss)/len(valid_set)\n",
        "    loss_val_list .append(final_valid_loss_mean)\n",
        "    print('-'*70)\n",
        "    print('-'*70)\n",
        "    print(time.ctime())\n",
        "    print(\n",
        "        f'Epoch {epoch}:', '\\n', f'training step:{total_step}, train loss: {final_train_loss_mean:.7f}, valid loss: { final_valid_loss_mean:.7f}', \\\n",
        "        '\\n',f\"Learning rate:{cur_lr}\" )\n",
        "    print(f\"Train set accuracy: {final_train_acc:.7f}\")\n",
        "    print(f\"Valid set accuracy: {final_valid_acc:.7f}\")\n",
        "\n",
        "    # scheduler.step(final_valid_loss_mean)\n",
        "\n",
        "    # check if the loss on valid set is improved or not\n",
        "    if final_valid_loss_mean <= valid_loss_min: # and final_valid_acc <= valid_acc_min:\n",
        "        print('-'*10)\n",
        "        print('Validation loss decreased ({:.8f} --> {:.8f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            final_valid_loss_mean))\n",
        "        # torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        valid_loss_min = final_valid_loss_mean\n",
        "        valid_acc_best = final_valid_acc\n",
        "        best_model['Best epoch'] = epoch\n",
        "        best_model['model'] = model.state_dict() # assign this model since it perform better\n",
        "        best_model['Best Acc on validation set'] = valid_acc_best\n",
        "        best_model['Best(lowest) validation loss'] = valid_loss_min\n",
        "\n",
        "        # for k,v in best_model.items():\n",
        "        #   if k is not 'model':\n",
        "        #     print(f\"{k}: {v}\")\n",
        "        # print('-'*10)\n",
        "        p = 0  # reset P\n",
        "    else:\n",
        "        print('-'*10)\n",
        "        p += 1\n",
        "        print(f'{p} epochs of increasing validation loss')\n",
        "        if p >= 15:\n",
        "            print(f'Stopping training since no improvement on the validation loss over {p} epoches ')\n",
        "            stop = True\n",
        "            break\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total epoch num 75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:32:07 2021\n",
            "Epoch 0: \n",
            " training step:63, train loss: 0.0193936, valid loss: 0.0177461 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.3950249\n",
            "Valid set accuracy: 0.3479125\n",
            "----------\n",
            "Validation loss decreased (inf --> 0.01774611).  Saving model ...\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:33:16 2021\n",
            "Epoch 1: \n",
            " training step:126, train loss: 0.0166164, valid loss: 0.0161118 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.4199005\n",
            "Valid set accuracy: 0.5000000\n",
            "----------\n",
            "Validation loss decreased (0.01774611 --> 0.01611183).  Saving model ...\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:34:25 2021\n",
            "Epoch 2: \n",
            " training step:189, train loss: 0.0149556, valid loss: 0.0143619 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.5375622\n",
            "Valid set accuracy: 0.5596421\n",
            "----------\n",
            "Validation loss decreased (0.01611183 --> 0.01436186).  Saving model ...\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:35:34 2021\n",
            "Epoch 3: \n",
            " training step:252, train loss: 0.0136777, valid loss: 0.0132063 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.6032338\n",
            "Valid set accuracy: 0.6123260\n",
            "----------\n",
            "Validation loss decreased (0.01436186 --> 0.01320629).  Saving model ...\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:36:43 2021\n",
            "Epoch 4: \n",
            " training step:315, train loss: 0.0123382, valid loss: 0.0119771 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.6594527\n",
            "Valid set accuracy: 0.6640159\n",
            "----------\n",
            "Validation loss decreased (0.01320629 --> 0.01197706).  Saving model ...\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:37:52 2021\n",
            "Epoch 5: \n",
            " training step:378, train loss: 0.0108237, valid loss: 0.0116040 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.7151741\n",
            "Valid set accuracy: 0.6779324\n",
            "----------\n",
            "Validation loss decreased (0.01197706 --> 0.01160403).  Saving model ...\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:39:02 2021\n",
            "Epoch 6: \n",
            " training step:441, train loss: 0.0100496, valid loss: 0.0092945 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.7348258\n",
            "Valid set accuracy: 0.7624254\n",
            "----------\n",
            "Validation loss decreased (0.01160403 --> 0.00929452).  Saving model ...\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:40:10 2021\n",
            "Epoch 7: \n",
            " training step:504, train loss: 0.0088445, valid loss: 0.0104591 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.7703980\n",
            "Valid set accuracy: 0.7713718\n",
            "----------\n",
            "1 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:41:20 2021\n",
            "Epoch 8: \n",
            " training step:567, train loss: 0.0078742, valid loss: 0.0087582 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.8034826\n",
            "Valid set accuracy: 0.7753479\n",
            "----------\n",
            "Validation loss decreased (0.00929452 --> 0.00875819).  Saving model ...\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:42:29 2021\n",
            "Epoch 9: \n",
            " training step:630, train loss: 0.0074151, valid loss: 0.0082561 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.8156716\n",
            "Valid set accuracy: 0.7942346\n",
            "----------\n",
            "Validation loss decreased (0.00875819 --> 0.00825614).  Saving model ...\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:43:38 2021\n",
            "Epoch 10: \n",
            " training step:693, train loss: 0.0071253, valid loss: 0.0076422 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.8191542\n",
            "Valid set accuracy: 0.8081511\n",
            "----------\n",
            "Validation loss decreased (0.00825614 --> 0.00764224).  Saving model ...\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:44:47 2021\n",
            "Epoch 11: \n",
            " training step:756, train loss: 0.0066349, valid loss: 0.0070444 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.8308458\n",
            "Valid set accuracy: 0.8290259\n",
            "----------\n",
            "Validation loss decreased (0.00764224 --> 0.00704435).  Saving model ...\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:45:56 2021\n",
            "Epoch 12: \n",
            " training step:819, train loss: 0.0059615, valid loss: 0.0069508 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.8477612\n",
            "Valid set accuracy: 0.8310139\n",
            "----------\n",
            "Validation loss decreased (0.00704435 --> 0.00695080).  Saving model ...\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:47:05 2021\n",
            "Epoch 13: \n",
            " training step:882, train loss: 0.0057473, valid loss: 0.0073893 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.8547264\n",
            "Valid set accuracy: 0.8220676\n",
            "----------\n",
            "1 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:48:14 2021\n",
            "Epoch 14: \n",
            " training step:945, train loss: 0.0050740, valid loss: 0.0077283 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.8773632\n",
            "Valid set accuracy: 0.8061630\n",
            "----------\n",
            "2 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:49:23 2021\n",
            "Epoch 15: \n",
            " training step:1008, train loss: 0.0045493, valid loss: 0.0068686 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.8898010\n",
            "Valid set accuracy: 0.8419483\n",
            "----------\n",
            "Validation loss decreased (0.00695080 --> 0.00686862).  Saving model ...\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:50:32 2021\n",
            "Epoch 16: \n",
            " training step:1071, train loss: 0.0041583, valid loss: 0.0068383 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.8987562\n",
            "Valid set accuracy: 0.8439364\n",
            "----------\n",
            "Validation loss decreased (0.00686862 --> 0.00683829).  Saving model ...\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:51:41 2021\n",
            "Epoch 17: \n",
            " training step:1134, train loss: 0.0039861, valid loss: 0.0071298 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.9024876\n",
            "Valid set accuracy: 0.8369781\n",
            "----------\n",
            "1 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:52:50 2021\n",
            "Epoch 18: \n",
            " training step:1197, train loss: 0.0032033, valid loss: 0.0076267 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.9213930\n",
            "Valid set accuracy: 0.8240557\n",
            "----------\n",
            "2 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:53:59 2021\n",
            "Epoch 19: \n",
            " training step:1260, train loss: 0.0027330, valid loss: 0.0080633 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.9363184\n",
            "Valid set accuracy: 0.8270378\n",
            "----------\n",
            "3 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:55:09 2021\n",
            "Epoch 20: \n",
            " training step:1323, train loss: 0.0027845, valid loss: 0.0079106 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.9373134\n",
            "Valid set accuracy: 0.8200795\n",
            "----------\n",
            "4 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:56:18 2021\n",
            "Epoch 21: \n",
            " training step:1386, train loss: 0.0031634, valid loss: 0.0080978 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.9261194\n",
            "Valid set accuracy: 0.8190855\n",
            "----------\n",
            "5 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:57:27 2021\n",
            "Epoch 22: \n",
            " training step:1449, train loss: 0.0016402, valid loss: 0.0098047 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.9676617\n",
            "Valid set accuracy: 0.8379722\n",
            "----------\n",
            "6 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:58:36 2021\n",
            "Epoch 23: \n",
            " training step:1512, train loss: 0.0027213, valid loss: 0.0096839 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.9310945\n",
            "Valid set accuracy: 0.8210735\n",
            "----------\n",
            "7 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 08:59:45 2021\n",
            "Epoch 24: \n",
            " training step:1575, train loss: 0.0011091, valid loss: 0.0096966 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.9805970\n",
            "Valid set accuracy: 0.8389662\n",
            "----------\n",
            "8 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 09:00:54 2021\n",
            "Epoch 25: \n",
            " training step:1638, train loss: 0.0007015, valid loss: 0.0119741 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.9853234\n",
            "Valid set accuracy: 0.8210735\n",
            "----------\n",
            "9 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 09:02:03 2021\n",
            "Epoch 26: \n",
            " training step:1701, train loss: 0.0005753, valid loss: 0.0115811 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.9895523\n",
            "Valid set accuracy: 0.8280318\n",
            "----------\n",
            "10 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 09:03:12 2021\n",
            "Epoch 27: \n",
            " training step:1764, train loss: 0.0016383, valid loss: 0.0093677 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.9654229\n",
            "Valid set accuracy: 0.8210735\n",
            "----------\n",
            "11 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 09:04:21 2021\n",
            "Epoch 28: \n",
            " training step:1827, train loss: 0.0005041, valid loss: 0.0123459 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.9935324\n",
            "Valid set accuracy: 0.8290259\n",
            "----------\n",
            "12 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 09:05:30 2021\n",
            "Epoch 29: \n",
            " training step:1890, train loss: 0.0003481, valid loss: 0.0133760 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.9940299\n",
            "Valid set accuracy: 0.8270378\n",
            "----------\n",
            "13 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 09:06:39 2021\n",
            "Epoch 30: \n",
            " training step:1953, train loss: 0.0015755, valid loss: 0.0107872 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.9659204\n",
            "Valid set accuracy: 0.8230616\n",
            "----------\n",
            "14 epochs of increasing validation loss\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Fri Oct 22 09:07:48 2021\n",
            "Epoch 31: \n",
            " training step:2016, train loss: 0.0004168, valid loss: 0.0130543 \n",
            " Learning rate:0.0001\n",
            "Train set accuracy: 0.9940299\n",
            "Valid set accuracy: 0.8280318\n",
            "----------\n",
            "15 epochs of increasing validation loss\n",
            "Stopping training since no improvement on the validation loss over 15 epoches \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX_mrlHG7Akh"
      },
      "source": [
        "plot the graph "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDk9vSTZ7Aki",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "d6533643-5683-45fc-cdec-ac6179e091c7"
      },
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.suptitle(model.to_model_string()+\" by using Adam as optimizer,fixed different learning scheldar for every batches\")\n",
        "\n",
        "plt.subplot(1, 2, 1).set_title('loss')\n",
        "plt.plot(loss_train_list, color='blue', label='train set')\n",
        "plt.plot(loss_val_list, color='red', label='valid set')\n",
        "plt.subplot(1, 2, 2).set_title('Accuracy')\n",
        "plt.plot(acc_train_list, color='blue', label='train set')\n",
        "plt.plot(acc_valid_list, color='red', label='valid set')\n",
        "print('Finished the training process and plot graphs')\n",
        "print(\"RED is for validation set, BLUE is for train set \")\n",
        "plt.show()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished the training process and plot graphs\n",
            "RED is for validation set, BLUE is for train set \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAFTCAYAAACTc8AJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5gUxdbA4d8hB5GskoOIiAkkCiooesWICCrBgHIxYuYzo6B4BVFBL+aEioCKiqgYLgqiKEpSSQZEkJyRHHb3fH+cHmmG2d3ZOBvO+zzzzEx3TXVNT0/PmarqKlFVnHPOOedc4hVJdAGcc84555zxwMw555xzLo/wwMw555xzLo/wwMw555xzLo/wwMw555xzLo/wwMw555xzLo/wwCyPEJElInJ6Ard/soj8mqjth4nIABEZlehyJIqIPCci/TP52ntE5KXsLlOM7RwqIlNFZKuIPJ5T2xWRKSLy7zjTtheR5aHn80WkffBYRORVEdkkIj8Ey64TkTUisk1EKmd32bMi+r3k8rYzffxlt6zsh/ReKyIjRWRQ5kt3QH5HisiPwXfipuzKN6/J7v2WxnYS9h1INA/MYhCRHiIyMzhhrxKRT0TkpGDdABFREbk4lL5YsKxu8Hxk8LxlKE0DEcmzg8ap6teqemRObiPYL0kiUi0nt5OfiEgvEfkmvExVr1XVhzKTn6r+R1XjCmSy6GpgPXCwqt6ei9uNm6oerapTgqcnAWcANVW1pYgUB54A/qWqB6nqhtwsW6L/iKUlK8dfIXcHMFlVy6nqU4kuTF5U2P90x8sDsygichswHPgPcChQG3gG6BRKthEYKCJF08hqI5Dj/yryCxEpC3QB/gYuTXBxXAaISLEYi+sACzT/jFBdB1iiqtuD54cCpYD5mcksne9+npXKZ+kyIKh9jfXbWYfMH08J+1zy67FckHlgFiIi5YEHgRtU9T1V3a6qe1X1Q1X9v1DST4E9pB1gvAYcJyLtMlCEFiKyIGhueVVESgXlmici54XKWVxE1otI0xjv4YAamKD2rkHw+OxgG1tFZIWI9AuWRzcDLRGRfiLys4j8LSJvRcoTrL8jqE1cKSL/Dm8jFV2Azdj+vSKqfPVE5KugTP8DqkStf0dEVgflmCoiR4fWjRSRZ4JazW0iMk1EDhOR4cF+/CXWfgq9/kkRWSYiW0RkloicHFrXMqg53RI0eT2RRj59RGSRiGwUkQkiUj1q/98kIouDz22oiBQRkaOA54ATg7JvDr2nQcHj9iKyPNjfa4N9fkHwOf4WbO+e0Lb++UcqIiOCfCO3JBEZEKyrLiLvisg6EflTQk0vQR7jRGSUiGwBekW915HBZ3hHkO/pUdu9JMjz4OD5WcHnVzV4fpWILAw+n89EpE4o7zOCz+xvERkBSBr7vHSwrzaJyAKgRdT6JUHZegMvhfbzGCDSbL9ZRL4M0jcSkf8F+/RX2b9WfKSIPCsiE0VkO3BqHPvwbRF5PTiu54tI82DdG9gfvg+D8tyR2nsM5ZfWtlqKyHcisjk4PkaISInQehWRG0Tkd+D30DF1e+iYujLqvUYff6mlrSwiH4p9R2aIyCCJOv+E0pYKjqkNQVlniMihwbpKYue8lcHnOT7qtaltv6SIPCYif4l9R58TkdKpbL+piMwOPo+3sMA8sq6iiHwU7N9NweOaofVTRORhEZkG7ADqR+X9JXAqEPnONRSR8sHnv05ElorIfRIEdGLn6WkiMkxENgADYpS3iIjcJSJ/BPvsbRGpFKz7RET6RqX/SUQuDB5n5Fi+Ldh3RUNpLhSRn2Ltx0CVIP+tYufu8Hc45jlVRDoC9wCXBPvop2B5tn/2IlIl+Aw3B/vga4kdTOdNquq34AZ0BJKAYmmkGQCMAs4HFgPFgWKAAnWDNCOx2rKbgG+CZQ1sd6ea7xJgHlALqARMAwYF6+4A3gql7QTMTSWfXpFthpYp0CB4vAo4OXhcETgheNweWB5Vnh+A6kF5FgLXhvbTauBooEywP/7ZRirl+gJ4FKupSAKahdZ9hzUrlQROAbYCo0LrrwLKBeuHAz+G1o3EmtSaYSfaL4E/gcuBosHnMDmNcl0KVA4+w9uD91UqVK7LgscHAa1TyeO0oAwnBGX8LzA1av9PDvZjbeA34N9pfF4jQ599+2B/3Y8da32AdcDoYJ8cDewE6oWPzxhlbBK8rin2h2xWkGcJ7EdmMXBmKI+9wAVB2tIx8vunjLG2C7wZpKkMrATODR27i4Cjgn1+H/BtsK5K8Nl3Dd7rrcF7/3cq+30w8HWwX2th35/oY/j0WPsZqBt8LsWC52WBZcCVQbmaBp9p49D7/RtoG+yTMnHsw13A2dhx+AgwPVbZUnlv7SPvJY7PqxnQOih3Xey7ekvU8fe/YD+VZt8x9WCwn8/Ggo2KaRx/qaUdG9zKAI2DffhNKu/pGuDDIG3RoNwHB+s+Bt7CzknFgXZxbn8YMCF4b+WC/B+JsQ9LAEuxY6o4doztDb3PytifxzJBPu8A40NlnwL8hX3figHFY7y/KYSOVeB14IMgv7rY97536HhMAm4M8ov1HbsZmA7UxM4rzwNjgnWXA9NCaRtjf3xLkvFjuRSwADgrlN/7wO2pfI4jse/pKcH2nmT/71Za59QBRJ2fcuizfwT701s8uJ0MSGrft7x2S3gB8tIN6AmsTifNPwcW8D1wHakHZiWDL/NZxBeYXRt6fjbwR/C4evBFiJzExgF3pJJPL9IOzP7CTpAHR6Vpz4E/apeGnj8KPBc8fiXyBQieNyCNwAwLRlKAJsHzz4AnQ+uSgLKh9KOjv7yhdRWCbZUP7esXQ+tvBBaGnh8LbM7AMbAJOD54PBUYCFRJ5zUvA4+Gnh+EnfQjx4MCHUPrrwe+SOPzGsn+P4w7gaLB83JBfq1C6WcBF0Qfn6H1VYPPs1vwvBXwV1Sau4FXQ3lMTec9/1PGWNsNPqe/gLnA86HlnxD8OAXPi2An2zrYj004eBFgOakHZouj9uvVZD4wuwT4Oir/54EHQu/39dC6ePbhpNC6xsDOWGVL5b21Z19Qkea2Yrz2FuD90HMFTovKeyehP6DAWoI/HsQ+/g5IiwVXe4EjQ+sGkXpgdhXwLXBc1PJq2PmhYir7IbXtC7AdODy07kTgzxj78BTsD4KE0n5L6BiO2m4TYFPo+RTgwXS+E1PY94erKNaq0ji0/hpgSuh4/Cud/BYCHaL2017s96Zc8N7rBOseBl7JzLEcLLsTeDN4XAn7TlZLpVwjgbGh5wcByUCtVNKHz6kD2P88kVOf/YNYUJxqZUFevuWfqr3csQGroo23vf8+4F5CVeJhqrobeCi4xWNZ6PFSLCBDVVdiNWhdRKQCFui9GWee0bpgQd/SoAr6xDTSrg493oF9AQnKFS5r+HEsl2HB0o/B8zeBHmIdsKtjJ8DtofRLIw9EpKiIDA6q87dgP2iwf3PnmtDjnTGeH0QqxJprF4o1nW0Gyofy7g00BH4Jml3OTSWb6uEyq+o27FiqEUoT87ON0wZVTQ69H4jzPQb7eBwwWlXHBovrANWDav7Nwfu+B6vNjFXeDFPVzVitwzHA46FVdYAnQ9vdiJ1kaxB1XKmdYdMqR/RxuDS1hHGoA7SK2ic9gcNCaZZFpU9vH0Z/f0pl4NwSXbZUtxU0m30k1ly8BesfWyUqj+j9uEFVk6LKl9r3JLW0VbEgId5zwRvYn7KxQbPVo8HxWQvYqKqbMrH9MsCs0H75NFgerTqwIjimIsLnmTIi8nzQ5LgF+1NWQfbvf5WR70QVrKYmfEwuJfVzQix1gPdD720hFgAdqqpbsZqmbkHa7uz7TcjosQzW6nGeWF/gi7HAblUaZQt/T7dh3+PqkO45NVpOffZDsZr5z8W6kNyVxnvJczww2993wG6sCSddqvo/7MO/Po1kr2K1BxfGkWWt0OPa2D+8iNewKuKLgO9UdUUqeWzHDlgARCT8ZURVZ6hqJ+AQYDzwdhzlirYKq16PVe5YLgfqBz8cq7FmyypYgLgKqBicECJqhx73wJq/Tse+4HWD5an2PYpX0PfhDuxEVFFVK2BV/AKgqr+randsXw0BxkWVM2IldjKM5FsWq8oPf0apfbbhH4qc8F9gC/YnImIZ9s+yQuhWTlXPDqXJUrlEpAlWQzIGCF+htgy4JmrbpVX1W+xYqBXKQ0j72FrFgfs1s5YBX0WV6yBVvS6URqPSp7cP05KR/Zvetp4FfgGOUNWDsaAt+vuRE8fZOqy2O65zgVp/3YGq2hhoA5yLnRuWAZWCP50ZsR77U3J0aL+UV9VYAeYqoEZwTEWEj5fbgSOxmuiDsRo22H8/ZmQfrsdqt+qEltVm/3NCevktw5oXw597qdC5fwzQPfhzXQrrLhF5XUaOZYI8v8N+py7Dgui0hL+nB2G1bCvTO6fGeM858tmr6la1q8XrY92ObhORDhncRsJ4YBaiqn9j/TieFutgXUaso/1ZIvJoKi+7FzsQU8szCXgAqypOzw0iUlOsg+e9WLt7xHisD9PNWN+F1PwEHC0iTcQ66w+IrBCREiLSU0TKq+pe7Ac7JY5yRXsbuFJEjhKRMkCqYx4FJ43DgZZY80ATrBZlNHC5qi4FZmJXuZYQG5bkvFAW5bBgeQMWcP4nE+VNTTnsh2UdUExE7gcODpX9UhGpqqopWP8NiL2/xmD7o4mIlAzK+L2qLgml+T+xDsa1sM8w8tmuAWpKqLN2dhGRa4B2QM/gPUT8AGwVkTvFOtAXFZFjRKRF7Jz+6QQe1w9TcNyNwgKEK7EfxMifl+eAuyW4gEOsg/RFwbqPsWP3wqBm6Sb2/5cf7e0gr4piHbVvjKd8qfgIaCgilwXf+eIi0kLsAo1YMrwPo6whqgN5GtLbVjnsu7xNRBph3StyXFCL+x4wIDhXNsICrZhE5FQROTaohdqCBS4pQc3MJ8AzwWdZXEROSS2f0PZTgBeBYSJySLCNGiJyZozk32Hf9ZuC/C/EzkkR5bAf+s3B+feB9PdAmmVLxo7Ph0WknFjn+Nuw70W8ngteXwdARKqKSHh0gIlY4Pcg1gc58h3P6LEc8Tr2W3Ys9rmm5WwROSk4bz2EdUFYRjrnVOy4rytBR/yc+uxF5FyxIaoECwyTydxvXUJ4YBZFVR/HvkD3YQfXMqAvFhjFSj8NO3GmZQz2jy09o4HPsb4zfxAabkNVdwLvAvVI40ujqr9hX9RJwO9A9BVSlwFLxKrrr8WquDNEVT/BakEmYzWG04NVu2MkvwL4QFXnqurqyA3rMHpucBLsgfWj2YidEMOB5+tYE8AKrIPqdLLPZ1j192/BNnaxfxV/R2C+iGwLytst+Bz2o6qTsOD0XexzPpx9TQwRH2B9wX7EApCXg+VfYpfYrxaR9dnztv7RHfvxXyn7rsy8J/jROBcLkv/E/n2+hNVIpqYW1icnHo8Ay1T12aA5/1JgkIgcoarvY7WPY4NjcB7WNI+qrsdqhAdjgfgRWBN+agZin9uf2PcmvX/5qQqahv6FfW4rsWbIIVg/0VjpM7MPwx4B7hNrhumXTtnS21Y/7Du0FfuxeitGNjmlb1CO1dj+H0Ps8wBYkD0OC8oWAl+x7zO7DAvUfsH6Ed0S5/bvJDgHBcfTJKzmaz+qugerDeqFnWcuYf/z6HDswoj12Dnm0zi3n5YbsRaMxdh5eDTWPzdeT2Kd2z8Xka1BuVpFVgbfrfew1oTRoeUZOpZD3idoPlXVHemkHY2dqzdiF3FERihI75z6TnC/QURmB49z4rM/Ini+DQvKn1HVyTFzyYNk/yZ3l5cF/z4aqmqeGgcs+Cc2DygZ1R/AYcMVYM1MixJdlswSG9X/HVX9LNFlcXmXiAwBDlPVKxJdFpdxIvIH1tVgUqLLUpj5YIP5RFCz1Bv7d5FwItIZq0ovg/0b+9CDsoJL89io/i5vCJovS2BX37bAzlF+rORDItIF6wP2ZaLLUth5U2Y+ICJ9sOrgT1R1aqLLE7gGq3b+A2u/z5V+Lc65PKUc1py2HWtCfRxrtnf5iIhMwS4iuSGqP6pLAG/KdM4555zLI7zGzDnnnHMuj/DAzDnnnHMuj/DAzDnnnHMuj/DAzDnnnHMuj/DAzDnnnHMuj/DAzDnnnHMuj/DAzOU5IrJERE5PdDmcc8653OaBmXPOOReDiEwRkU0ikt48k85lGw/MnHPOuSgiUhc4GZum6Pxc3K5PlVjIeWDm8iwRKSkiw0VkZXAbHvnnKiJVROQjEdksIhtF5GsRKRKsu1NEVojIVhH5VUQ6JPadOOfyocuB6cBI4J9J2UWkloi8JyLrRGSDiIwIresjIguDc88CETkhWK4i0iCUbqSIDAoetxeR5cF5azXwqohUDM5v64Iau49EpGbo9ZVE5NXgvLhJRMYHy+eJyHmhdMVFZL2INM2xveSynQdmLi+7F2gNNAGOB1oC9wXrbgeWA1WBQ4F7ABWRI4G+QAtVLQecCSzJ3WI75wqAy4E3g9uZInKoiBQFPgKWAnWBGsBYABG5CBgQvO5grJZtQ5zbOgyoBNQBrsZ+m18NntcGdgIjQunfAMoARwOHAMOC5a8Dl4bSnQ2sUtU5cZbD5QFeZerysp7Ajaq6FkBEBgLPA/2BvUA1oI6qLgK+DtIkAyWBxiKyTlWXJKLgzrn8S0ROwoKit1V1vYj8AfTAatCqA/+nqklB8m+C+38Dj6rqjOD5ogxsMgV4QFV3B893Au+GyvMwMDl4XA04C6isqpuCJF8F96OA/iJysKpuAS7DgjiXj3iNmcvLqmP/TCOWBssAhmInvs9FZLGI3AUQBGm3YP9c14rIWBGpjnPOxe8K4HNVXR88Hx0sqwUsDQVlYbWAPzK5vXWquivyRETKiMjzIrJURLYAU4EKQY1dLWBjKCj7h6quBKYBXUSkAhbAvZnJMrkE8cDM5WUrsX+tEbWDZajqVlW9XVXrY00Gt0X6kqnqaFWN/ONVYEjuFts5l1+JSGngYqCdiKwO+n3dinWnWAPUTqWD/jLg8FSy3YE1PUYcFrVeo57fDhwJtFLVg4FTIsULtlMpCLxieQ1rzrwI+E5VV6SSzuVRHpi5vGwMcJ+IVBWRKsD9WFU9InKuiDQQEQH+BpKBFBE5UkROCy4S2IU1CaQkqPzOufznAux80hjr39oEOArrLnEBsAoYLCJlRaSUiLQNXvcS0E9EmolpICKRP5Y/Aj1EpKiIdATapVOGcti5a7OIVAIeiKxQ1VXAJ8AzwUUCxUXklNBrxwMnADdjfc5cPuOBmcvLBgEzgZ+BucDsYBnAEcAkYBvwHfCMqk7G+pcNBtYDq7GOsXfnbrGdc/nYFcCrqvqXqq6O3LDO992B84AGwF/YBUiXAKjqO8DDWLPnVixAqhTkeXPwus1Y39nx6ZRhOFAaO49NBz6NWn8Z1s/2F2At1n2DoByR/mn1gPcy+N5dHiCq0TWozjnnnMuvROR+oKGqXppuYpfn+FWZzjnnXAERNH32xmrVXD7kTZnOOedcASAifbCLAz5R1amJLo/LHG/KdM4555zLI7zGzDnnnHMuj/DAzDnnnHMujygQnf+rVKmidevWTXQxnHO5aNasWetVtWqiy5FVfv5yrvBJ6/wVV2AWDIj3JFAUeElVB0etL4kNZNcMm7T1ElVdIiJnYGNKlQD2YPOLfRm8phkwEhurZSJws6pqcEXJW9gEsUuAi2NNPRFWt25dZs6cGc9bcc4VECKyNP1UeZ+fv5wrfNI6f6XblBnMzfU0NudWY6C7iDSOStYb2KSqDbBZ7iNT4KwHzlPVY7FB+8KTqT4L9MEGCj0C6Bgsvwv4QlWPAL4InjvnnHPOFXjx9DFrCSxS1cWqugcYC3SKStMJm58LYBzQQUREVecEk6oCzAdKi0hJEakGHKyq09UuC30dm+oiOq/XQsudc8455wq0eAKzGti4KBHLg2Ux06hqEjZ3YeWoNF2A2aq6O0i/PJU8Dw3mAgObUufQWIUSkatFZKaIzFy3bl0cb8M555xzLm/LlasyReRorHnzmoy8LqhNiznQmqq+oKrNVbV51ar5vv+vc84551xcgdkKoFboec1gWcw0IlIMKI9dBICI1ATeBy5X1T9C6WumkueaoKmT4H5tvG/GOedykoi8IiJrRWReKutFRJ4SkUUi8rOInJDbZXTO5W/xBGYzgCNEpJ6IlAC6AROi0kzAOvcDdAW+DK6wrAB8DNylqtMiiYOmyi0i0lpEBLgc+CBGXleEljvnXKKNZN+FSrGcxb4Lmq7GLnJyzrm4pRuYBX3G+gKfAQuBt1V1vog8KCLnB8leBiqLyCLgNvZdSdkXaADcLyI/BrdDgnXXAy8Bi4A/gE+C5YOBM0Tkd+D04LlzziVcMP/gxjSSdAJeVzMdqBBpAXDOuXjENY6Zqk7ExhoLL7s/9HgXcFGM1w0CBqWS50zgmBjLNwAd4imXc87lMaldLLUqdnLnnNufT8nknHO5zK8qd86lpkBMyRSvjRvhvfegQweoVy/RpXHOFUDxXCyFqr4AvADQvHnzmFeeO+eyV3IyzJkDO3fC7t2wZ4/dRx4XKQKdO0PZshnP94kn4Lrr4KCDsl7OQhWYbdoEffrA88/D1VcnujTOuQJoAtBXRMYCrYC/Q+MyOucS6PLLYfTotNN07gzvvgsi8ec7dCjcfbdV+HTtmrUyQiELzOrXh0qVYMYMD8yccxknImOA9kAVEVkOPAAUB1DV57C+uGdjFzXtAK5MTEmdK1jWrYPvv4fp02H9enjssYzVTo0da0HZLbfAuedCyZJQosT+92PHwr33wuuvwxVXpJ8nwI8/wv33w0UXQZcumXtv0QpVYCYCzZtbYOaccxmlqt3TWa/ADblUHOcKpD17LOCZPt1u338PixfbuqJFISUFNmyAt9+Or2ZrxQprZmzd2mq3iqUS+dx1F3z+Odx4I7RrB3Xrpp3vrl1w6aVQpQo8+2zGatnSUug6/7doAfPmwY4diS6Jc84553bsgC++gAcegFNPhfLloVUruPlm+PpraNrUAqqpU2HLFhgyBMaNg8FxDKalClddZcHe66+nHpSB9TF7LZipu1cvCwDTct99MH8+vPwyVI6ehDILClWNGVhglpxs0XibNokujXPOOVf4fPEF/O9/FmzNmAFJSRYYNW1qtVtt21pwVrPmga/t18868d97Lxx3HJxzTurbeeYZqwV79lk44oj0y1WnDjz1FFx5JQwbBrffHjvdV19Zh/9rr4WzzorvPcdLrOY9f2vevLnOnDkzrrQrV0KNGjB8uEXjzrn8SURmqWrzRJcjqzJy/nKuIBg/3jrZFy9ulSWnnGK3Nm2stiweO3bASSfBH3/ADz/AkUcemObXXy3Qa98ePv44/qZGVbjwQpg4EWbNgmOiRlzdssUCwuLFrZIno1dxQtrnr0JXY1a9ut38POicc87lvmeegdq1YcGCzAU1AGXKwPvvW7/xCy6wfmgHH7xv/d69cNllULq0NTVmpP+XCLzwggVkl15qeZcsuW/9zTfDsmUwbVrmy5+WQtfHDPwCAOeccy4R/vzTmjCvuirrQU2dOvDOO/D77xZAhfuE/ec/9jv/3HNQLROTolWtCi+9BD/9BAMG7Fs+fjyMHGnDY7RunbXyp6ZQBmYtWlgV599/J7okzjnnXOHxyitWI3XVVdmTX/v21hfsww9h4EBbNmMGPPQQ9Oxpw1hk1nnnQe/e8OijVju2Zo2Nhdq0qQ2RkVMKbWAG1nbsnHPOuYyLdNqPV1KSBWYdO0KtWumnj1ffvtZZ/8EH4c03rQmzWjUYMSLreQ8bZjVzl19u29i6FUaNsrHPckqhDMyaB93tvDnTOeecy7gpU6Bly/iGrIj49FO7AK9Pn+wti4j1W2vZ0po0f/3VmhsrVMh63uXK2RAaf/4Jn3wCjzwCjRtnPd+0FMrArHJlmwXAAzPnnHMu4x55xO6HDrWR+OPx4otw6KE28n52K1XK5sKuX9/6f3XokH15n3yyDY3Ru3fujOZQ6K7KjGjRwkYUds4551z8Zs+2scGuuALeeMNqzR57LO3XrFxpQ1b062fDTOSEGjVg0aLsG4E/7JZbsj/P1BTKGjOwwGzpUpt/yznnnHPxGTLEhqZ48kkLzkaMsOEj0jJypA3u3rt3zpYtJ4Ky3FZoAzPvZ+acc85lzKJFNh3SddfZYLADBtiArJErImNJSbGhJ9q3j2/0/cKu0AZmJ5xgkbUHZs4551x8HnvMmiIjfa1q14YbboBXX4WFC2O/ZvJk6zyf3Z3+C6pCG5iVKwdHHeWBmXPOORePVassAOvVa/9BW+++2waLve++2K978UWoWNGmOXLpK7SBGVg/sxkzrBrWOeecc6l78kkbi6xfv/2XV61qy957z+atDFu/3qZOuuwyu3LSpa/QB2Zr18Ly5YkuiXPOOZd3/f03PPusjaTfoMGB62+91QK0u+7av7LjjTdgzx74979zr6z5XaEPzMCbM51zzrm0PPssbNkCd94Ze325ctC/v/UnmzTJlqlaM2arVnDssblX1vyu8AVmmzdb+A4cf7x1YvTAzDnnnItt504YPhzOPNPmiUzN1VdD3brW5ywlBb77zi4I8E7/GRPXALMi0hF4EigKvKSqg6PWlwReB5oBG4BLVHWJiFQGxgEtgJGq2jdIXw74OpRFTWCUqt4iIr2AocCKYN0IVX0pk+9vfz/+aKH72LHQuTMlS1oU74GZc865gmjLFhsMdvNmm+cx+rZjB5x/vo1HViSVqprXXrMJvO+6K+1tlSxp81Vefjm8+y5MnAgHHQSXXJL976sgSzcwE5GiwNPAGcByYIaITFDVBaFkvYFNqtpARLoBQ4BLgF1Af+CY4AaAqm4FmoS2MQt4L5TfW5EgLlsdc4xNnjV6NHTuDFhz5tixFt2ndlA655xz+c2PP0LXrvDHH/svL13amh7LlbNBX8ePh6efts79bdvunzYpyaZdatkS2rVLf5s9esCjj1qt2apV0LOnBWcufvGEIi2BRaq6WFX3AGOBTlFpOgGvBY/HAR1ERFR1u6p+gwVoMYlIQ+AQ9q9ByxnFilno/uGH9jcCC8z+/tsGzXPOOecKgpdfhtatYdcum0XAH/EAACAASURBVDz8r79g0ybYu9dqydassd+9xYth1ChYvRpOOgm6d7e0Ee++a2nuuiu+UfWLFoX//MeCwR07vBkzM+IJzGoA4ckWlgfLYqZR1STgb6BynGXohtWQhQet6CIiP4vIOBGpFWc+8enRA3bvtr8I7LsAYObMbN2Kc845l+t27ICrrrKrIE86yea1PPNMqFXLGoyKRbWTiVit1q+/wv33209jo0Y2ov/27TYP5pFHQqfo6pg0nHuu1a61aLFvlh0Xv7zQeNcNGBN6/iFQV1WPA/7Hvpq4/YjI1SIyU0RmrsvIhJetWkG9etacCTRubNW63s/MOedcfrZoEZx4og0C278/fPYZHHJIfK8tW9amVfrlF+tzNnAg1KljzaF33pmxrj4i1r/syy8LxtyVuS2eXb0CCNda1WRfx/wD0ohIMaA8dhFAmkTkeKCYqs6KLFPVDaq6O3j6EnZBwQFU9QVVba6qzatWrRrH2/hno1ZXO2kSrFlDsWI2PZMHZs455/Kr99+HZs1sXM6JE60TftGiGc+nTh3rdz11qj1u2NBq1DKqTBnvW5ZZ8QRmM4AjRKSeiJTAargmRKWZAFwRPO4KfBnVNJma7uxfW4aIhCZ64Hwgldm3sqBHD+vx+M47gFW3zp5tnRydc865/CIlxfp/XXihNTnOng1nnZX1fE8+GWbNggULoESJrOfn4pduYBb0GesLfIYFSW+r6nwReVBEzg+SvQxUFpFFwG3APxfVisgS4Amgl4gsF5HGoewvJiowA24Skfki8hNwE9ArU+8sLUcfDccd909zZvPmNk7LggXpvM4555zLI1JS4NprYcgQu//6a6vlyk6ZqXVzWRPXOGaqOhGYGLXs/tDjXcBFqby2bhr51o+x7G7g7njKlSU9etjfjD//pEWLeoA1Zx53XI5v2TnnnMuS5GTo3dvGGLv3XnjoIe/PVVDkhc7/idGtm92PHUuDBlC+vF+Z6ZxzLu/buxcuvdSCsgcfhEGDPCgrSApvYFanjo2kN3o0RYpYc6ZfAOCccy4v27PH6hXGjrWhLPr3T3SJXHYrvIEZWHPmvHkwdy4tWsDPP9sQZ84551xes3u3jeT/3nswbFjqE4q7/K1wB2YXXWQ9G0ePpkULqx7+6adEF8o5l1eJSEcR+VVEFonIATMHikgdEfkiGCB7iojUTEQ5XcGzc6cN8vrhh/DMM3DLLYkukcsphTswq1oV/vUvGDOGFs1SAG/OdM7FFpo3+CygMdA96ipzgMeA14MBsh8EHsndUrqCZts2mDbNRtP//HObaum66xJdKpeT4roqs0Dr3h0uv5yay77jkEPaemDmnEvNP/MGA4hIZN7g8EA7jbEhgwAmA+NztYQuX1u/HubM2XebPRt+/x1UrXHn9det078r2Dwwu+ACKFUKGTuG1q3bMmWKfQn8ChfnXJRY8wa3ikrzE3Ah8CTQGSgnIpVVdb+ZUETkauBqgNq1a+dYgV3et3cvvPUWPP64TX8UUacONG1qo+43bWoDoR92WOLK6XJP4W7KBChXziYGe/ttupy/l6VL4fvvE10o51w+1Q9oJyJzgHbYdHXJ0YkyPaWcKzC2bYPhw+Hww+GyyyxAGzIEvvgCNmyAJUtsmqX774fzzvOgrDDxwAzs6sx16+hS4QtKlrTLkJ1zLkq68war6kpVvVBVmwL3Bss2514RXV63erUNCFurFtx6K9SvDx99ZKMC3HEHnHYaVKqU6FK6RPLADKBjR6hQgbIfjObss61aOfmA/7jOuUIu3XmDRaSKiETOq3cDr+RyGV0etWYNXHMN1K0LjzxiAdj06TBlCpxzDhTxX2MX8EMBoGRJ6NIF3n+fnp13sHo1TJ2a6EI55/KSOOcNbg/8KiK/AYcCDyeksC7PUIVXX4WjjoKRI+GKK+CXX+Ddd6FVdA9F5/DAbJ8ePWDbNs7lI8qW9eZM59yBVHWiqjZU1cNV9eFg2f2qOiF4PE5VjwjS/FtVfcjqQuyPP+CMM+Cqq+Doo22czOefh4YNE10yl5d5YBbRrh1Uq0bJd0fTqROMG2dTXzjnnHMZkZQEQ4fCscfCDz/As8/CV19Bo0aJLpnLDzwwiyhaFC6+GD79lJ7nb2XjRpg0KdGFcs45l5/Mng0tW1pH/n/9CxYuhGuv9T5kLn5+qIR17Qq7d/OvvR9ToQKMGZPoAjnnnMsvnnjCgrJVq6zV5f33oUaNRJfK5TcemIW1aQPVqlFs/Di6dIHx421+Mueccy4tb74Jt99u81kuWGDXk/lA5S4zPDALK1IEOneGiRPpecF2tm2DiRMTXSjnnHN52ddfWwf/du1g9GioWDHRJXL5mQdm0bp2hZ07OWXHJxx6qDdnOuecS93vv9vMfnXrwnvv2ehLzmWFB2bRTj4Zqlal6HvjuOgi+Phj2LIl0YVyzjmX12zYsG9w2IkTfcR+lz08MItWrJg1Z378MT0v3MmuXfDBB4kulHPOubxk9277qfjrL+uPfPjhiS6RKyg8MIula1fYto2Wmz+ndm0fbNY559w+qtC7t/UtGzkS2rZNdIlcQeKBWSzt20OlShR5bxyXXAKff25V1s4559zAgXYV5sMPQ7duiS6NK2g8MIuleHHrzTlhAj267CYpyeY1c845V7i98YYFZldeCXffnejSuILIA7PUdOkCW7Zw/LpJNGzozZnOOVdYbdoEL7wAp5wCl18Op50Gzz3n45S5nBFXYCYiHUXkVxFZJCJ3xVhfUkTeCtZ/LyJ1g+WVRWSyiGwTkRFRr5kS5PljcDskrbxyXYcOUL488u44uneHKVNg5cqElMQ551wu27XLWkouvBAOOwyuuQbWrYNBg6yzf4kSiS6hK6jSDcxEpCjwNHAW0BjoLiKNo5L1BjapagNgGDAkWL4L6A/0SyX7nqraJLitTSev3FWyJJx/PnzwAZdcuBdVeOedhJTEOedcLlm0CPr0sWCsa1f47ju44QaYNctG9L/3XihXLtGldAVZPDVmLYFFqrpYVfcAY4FOUWk6Aa8Fj8cBHUREVHW7qn6DBWjxiplXBl6ffbp2hU2bOGr1ZI4/3psznXOuIPv6a2jVygYW79TJLvxavtzmwDzhBG+6dLmjWBxpagDLQs+XA61SS6OqSSLyN1AZWJ9O3q+KSDLwLjBIVTXevETkauBqgNq1a8fxNjLhX/+Cgw6CcePo3v1f3HUX/PGHj1fjnHMFzdixcMUVUK+eDRZbv34ObOSnn+CXX6xfzMqVsGLFvscrV0L16tCjB/TsCUcckQMFcPlBIjv/91TVY4GTg9tlGXmxqr6gqs1VtXnVqlVzpICUKgXnnQfvv0/PS5IoVgxGjEj/Zc455/IHVRg8GLp3h9at4dtvcygomzABmjSx8TVuu81+TH74AVJSrDquTx+oXRsefBAaNrSqu//+F9auTT/v/GjPnkSXIM+KJzBbAdQKPa8ZLIuZRkSKAeWBNEf+UtUVwf1WYDTWZJqpvHJU166wfj01F0/lkkvgpZdg8+aElcY551w2SUqCa6+1YS+6d7emyxyZVikpCe68Exo1gnnz7DLPHTusQ9vUqVZdN2wYTJoEy5bB0KEWuNx0k9WinXWWpUlJyYHCZdLq1TbK7vTpGXudKgwZYq1RTz2VM2XL5+IJzGYAR4hIPREpAXQDJkSlmQBcETzuCnwZNEvGJCLFRKRK8Lg4cC4wLzN55biOHaFMGRg3jttvh23bLDhzzjmXf23dag0iL7wA99wDo0bl4ATkr7xiTZiPPAJHHw0VKqTeYa1GDejXD+bMgblz4f/+z6466N7dBj9ftCiHCpkBy5dDu3b2vk491WZvj0dKir2fu+6yqytuvhnuv9+CNbePqqZ7A84GfgP+AO4Nlj0InB88LgW8AywCfgDqh167BNgIbMP6pzUGygKzgJ+B+cCTQNH08krt1qxZM81RXbuqHnqoalKSnnqqas2aqnv25OwmnXNpA2ZqHOevvH7L8fOXO8Dy5apNmqgWLar64otRK5OTVffuzb6Nbdumethhqm3aqKakZC6P5GTVV19VLV9etXRp1WHDbFkiLFmiWr++arlyquPHq7ZurSqi+sQTab+/vXtVr7hCFVT79rUf0d697fm116omJeXaW8gL0jp/JfyklB23HD+xjR1ru2rqVP3wQ3v45ps5u0nnXNo8MHMZlZKiOmaMarvKc/XqkiP1114Pq95wg2rnzqqtWqnWqqVarJgFHf36qS5blvWNPvSQ/WhMm5b1vJYvVz3nHMuvbVvVX3/Nep4ZsWiRau3aqhUqqH7/vS3bsUO1S5d9AVesAGvHDtXzz7c0AwfuC+BSUlTvvNOWX3yx6q5dOVv+NWtUJ01SnTdPdePGzAfKsSQnZyhY9sAsq7ZsUS1VSvWmmzQ5WfXII1VPOCF7P1PnXMZ4YOYyYv581VNPVT2XCbqXovbzB6oVK6oefbTqGWeo9uqles89qt27W3Va8eJWyzN3buY2unatBXmdO2ffG0lJUX39dQuOSpVSffzxA4Oh5GTVpUtVP/9c9amnVAcPVv3ll6xt95dfVKtXV61cWXX27AO316+f7c/zzrNawojNm1VPOcVq1Z5+OnbeQ4faa884Q3Xr1thpdu9WnTDBArgjj1S99VbVWbPS/yFOSVH96iv7TIsX3/e5g+2/+vVVTzrJ8r3lFtWXX1b96af0a01TUlQXLFAdMcIC08qVVb/5Ju3XhHhglh0uuEC1Rg3V5GR9/nnbc5Mn5/xmnXOxeWDm4rFli8UMxYqpnnvQZN1brKSmtGip+ttvVpOTmj//VL3pJtUyZeyEf8459gOfkX/kN95oAV5Wg6JYVqywIAismbR/fwsujj/emjvDAUjk1qKF6vDhqqtXZ2xbc+dad55DDlH9+efU0z39tGqRIqrNmqmuWmXbadLEdv6YMWlv45VX7LUtW6quX2/LUlKspvG661QrVbL3ULmy6umn7wuyjjpKddAg1cWL989v82bV//7Xgm6wZuCbbrJgdexYa3rt10+1Rw/V9u1VGzbc91mD7cM2bVRvvln1jTdUFy5U/f131RdeUO3WzZqnI2lr17ag/scf496lHphlh1GjbHdNmqQ7dqhWrap67rk5v1nnXGwemLm0RJotq1e3U/eD58/Q5IPK2Q915Ic/HuvXW3Nk1aqWUatWqjNmpP+633+3gOSaazL/JtKTkmK/TRUrWlBTv77qWWdZbdJzz1ntwcqVFsQ9/rhq06b2HooWVT3zTAs4UquhipgzR7VKFdVq1Sw4Sc+HH1qAU6eO6uGH2+NPPonv/bz/vmrJkhZs3XOPar16+4Kkbt0s70gH7w0bVJ9/XvXkk/cFSG3bWg3hv/+9L8hq3txqwbZvT3/7ycnWPDxqlNWetW27f7AWuVWrZgHdSy+p/vFHpprP0jp/ia3P35o3b64zZ87M2Y3s3GmD2zRqBJMnM2AADBxoF9oceWTObto5dyARmaWqzRNdjqzKlfNXIbFjh13A+PPPdpXl5MnQtCm8csdCmvQ92eZSmjbNhqDIqJ074bXX4OGHYf16ePllGww2NZdcAh99ZFdRVquW+TcVj9277T6ey0oXLIA337Tb0qVQujTUqWP75uCD7T5yK1vWhiE46CD48kto0CC+8syaBeeea+X6+GM48cT438uUKTYd4vbtNmf1pZdC585pz4O1dCmMHm0f+oIF9p569LCxUJpn8RSRlGQ/9DNm2BAm7drZj34Wp4FI6/zlgVlGDB8Ot94KX33F2kanULs29OoFzz2X85t2zu3PA7PCbd06Gwz255/tNncu/P77vqG+KlWChx6CazoupegpbSE5Gb75JutTt6xbZ+NbTp0Kd9wB//kPFC26f5oZM6BlS+jf3waMzYtSUmwHjhtnMxBs3XrgbcsWC8YmToS6dTOW/8aNsHcvHHpoxsu2YoXt08MOy9jrVO0gOOQQG5IkD/PALLvs3GnzdRx9NHzxBX36WID+11+QU5MPOOdi88CscEpKsnFJ77/fKlXAYq3jjtv/Vr8+FFm3Bk46yWq4pk6FY4/NnkLs2WNjcD33HJx9ttXWlC9v61ThtNNg/nybwy+/z3iu6pOE5oC0zl+JnJIp/yld2v4hffklfPMNt90Gu3bBs88mumDOOVfwzZplMxXdfru1KH3zjVXsLFpkY5wOGAAXXmiVPEW2bIYzz7Q5KCdOzL6gDKBECTvxP/OMTRfQujX89put++QTa4574IH8H5SBB2UJ4IFZRl17rVWTDhzIUUfZn6Wnn7YAzTnnXPbbuhVuucVaB1etgnfese5bbdta96cDbN9ufZwWLIDx4zPWxykjrrvOplFat84ixk8+samXGjSAq6/OmW26As8Ds4wqU8amlJg0Cb79lttvtzlmR41KdMGcczlNRDqKyK8iskhE7oqxvraITBaROSLys4icnYhyFiQffACNG1vz5bXXwsKF1sUr1YqcOXOgWTP47jsYMwbOOCNnC9iunfUpq1XL/qnPm2f9zooXz9ntugLLA7PMuO4661Q2cCCnngpNmsATT/h0X84VZCJSFHgaOAubWq67iDSOSnYf8LaqNsXmFX4md0tZcGzdas2SF1wAFStaP/Wnn97XlesAKSnw+ONWc7V1qzUxdumSO4WtV88K2LMndOpkkaNzmeSBWWaULWuTzH7+OfL9dG67zf7FffppogvmnMtBLYFFqrpYVfcAY4FOUWkUODh4XB5YmYvlK1D697dWyMGDrW9Z69ZpJF65Ejp2tPPyOefYZZodOuRaWQFrUx01ygrt/bJcFnhgllnXXw9VqsDAgVxyCdSoYbVmzrkCqwawLPR8ebAsbABwqYgsByYCN+ZO0QqWefNgxAi45hrrspVmq+CECXYZ5jffwPPP21UAlSvnWlmdy24emGXWQQfZpUGffkqJH3/g+uut29nChYkumHMugboDI1W1JnA28IaIHHCeFZGrRWSmiMxct25drhcyL1O1kSgOPhgGDUoj4Y4d9ge5UyeoXRtmz7YO915b5fI5D8yy4oYbbBTDgQPp08cGXR4xItGFcs7lkBVArdDzmsGysN7A2wCq+h1QCqgSnZGqvqCqzVW1eVUfBHE/775rIxINGpRGxdfatdCmjQ1Z0a+fdfRv1ChXy+lcTvHALCvKlbNas4kTqbpkBt2724wdmzcnumDOJcCuXdYZqOCaARwhIvVEpATWuX9CVJq/gA4AInIUFph5lVicduywU+rxx1szZkyrVkH79jZu2Mcfw9Ch8U1F5Fw+4YFZVvXta5cMPfggN95ow+e8+mqiC+VcAtxyi10Rt2ZNokuSI1Q1CegLfAYsxK6+nC8iD4rI+UGy24E+IvITMAbopQVhepVcMmSIzaTy1FMHznIEwLJlcMopluiTT2x4CucKGA/Msurgg+G22+CjjzhBZ9G2rTVnJicnumDO5aL58+HFF+3A/+67RJcmx6jqRFVtqKqHq+rDwbL7VXVC8HiBqrZV1eNVtYmqfp7YEucff/5pgVm3bhZ7HWDJEhszbO1aGwqjXbvcLqJzucIDs+xw441Wa/bQQ9x0EyxebH/mnCs07rjDmvaLFy/QgZnLOf36WS3Z0KExVi5aZNHapk12lVWbNrlePudyiwdm2aF8eQvOPviAzo0WUqMG/Pe/iS6Uc7lk0iSbi/C++6BpU5g+PeN5LF9ufYdcoTRpko1yce+9ULNm1MpffrGgbMcOmDwZWrRISBmdyy0emGWXG2+E0qUpPnwo111nNe2//JLoQjmXw5KTrbd23br2HTjxRJueZu/ejOUzdKjNL5jR17l8b+9euOkmOPxw6xWyn3nzrMkyJcUmBm/SJBFFdC5XeWCWXapUgd69YdQorjlnOSVK+NAZrhB4/XUbZX3wYLsyrnVr2LnTlmXE5Mk2I7XPL1jojBhh4z8OGwaliiXB3Lnwyis2Rlm7dlCsmAVlxxyT6KI6lys8MMtOt98OKSlUeWMY3bvDyJHw99+JLpRzOWT7dmu+bNUKLr7Ylp14ot1npDlz3Tr7MW7fPtuL6PK2dT+vYsE9o3i/zi2cO7itXUx13HH2J/fNN6F5c/jqKx+jzBUqHphlp7p17ZKi55/nlss3sn27BWfOFUiPP25zFD7xxL7R1mvXhmrVMnYBwFdf2f2pp2Z/GV3etGABXHUVFZvW4cVdl3H+mhcQERu8bNQo6weyaRN89pk1cTtXiMQVmIlIRxH5VUQWichdMdaXFJG3gvXfi0jdYHllEZksIttEZEQofRkR+VhEfhGR+SIyOLSul4isE5Efg9u/s/42c9Gdd8L27TT59hnatLGLAFJSEl0o57LZqlXw6KPQtev+V8iJWHNmRgKzKVOgbFmrHXEFlyp8/TWcdx4cfTQpY8byXMo1PHbZjxTZusXmuhw2DHr2hCOPhCJeb+AKp3SPfBEpCjwNnAU0BrqLSOOoZL2BTaraABgGDAmW7wL6A/1iZP2YqjYCmgJtReSs0Lq3gjGAmqjqSxl6R4l27LE26OFTT3HrNTv44w8fOsMVQPffD3v2WN+yaCeeaGPGrF0bX16TJ8PJJ3v/soIqOdkuuWzTxq6unD4dBgyg50l/0b/Cf7lq+PHWj8w5B8RXY9YSWKSqi1V1DzAW6BSVphPwWvB4HNBBRERVt6vqN1iA9g9V3aGqk4PHe4DZ2LxzBcOdd8K6dXTe/CrVq/vQGa6AiXTO7tvXLqWLlpF+ZmvWWLOW9y8rmLZssSFUunSxQP3pp2HpUr48+QHGTqrCvffadMPOuX3iCcxqAMtCz5cHy2KmCaYt+RtIbfrZ/YhIBeA84IvQ4i4i8rOIjBORWqm8NO86+WQ48USKDnuM669O4rPP4NdfE10o57LJHXdYJ+377ou9vlkzqwGJpzlzyhS79/5lBdOXX1ogP2KEzW15/fWklCrDHXdYd8S+fRNdQOfynoQ24otIMWw+uadUdXGw+EOgrqoeB/yPfTVx0a+9WkRmisjMdevy2BzBIlZrtmQJfQ9524fOcAXH55/Dp59C//6pV3WULm3jTcUbmJUrByeckK3FdHnEtGlQooRdZRlMfjl2rM11//DDUKpUgsvnXB4UT2C2AgjXWtUMlsVMEwRb5YENceT9AvC7qg6PLFDVDaq6O3j6EtAs1gtV9QVVba6qzatWrRrHpnLZeefBUUdR/vlH6XaJMnKk1eo7l6/ddx/Urw833JB2ushAs0lJaaebPNn6HXkfo4Lp22/too4gAtu9G+65x+L2Hj0SXDbn8qh4ArMZwBEiUk9ESgDdgAlRaSYAVwSPuwJfqqqmlamIDMICuFuillcLPT0fWBhHGfOeIkWsyeenn7ir6Wds2wbvvJPoQjmXBdu2wcyZcPnlNphsWk480abQmTs39TQrV1obv/cvK5h27bLjpW3bfxYFXcwYOtQvunQuNel+NYI+Y32Bz7Ag6W1VnS8iD4rI+UGyl4HKIrIIuA34Z0gNEVkCPAH0EpHlItJYRGoC92JXec6OGhbjpmAIjZ+Am4Be2fFGE6JHD6hZk0YfDKZRI3j11UQXyLks+PlnG/IgnmbH1q3tPq3mTO9fVrDNmmVX7gaB2aZNMGgQnHkmnH56gsvmXB4WV/uBqk4EJkYtuz/0eBdwUSqvrZtKtpJK+ruBu+MpV55XogTcdhty223cc/10Ln+mNb/9Bg0bJrpgzmXCnDl237Rp+mnr1oVDD7UrM6+/PnaaKVOgfHmf/7CgmjbN7oOrdB95BDZvhiFD0niNc85H/s9xffpAxYpctHgIRYv6TAAul+zYkf15zp5tc8LWiL4oOwYR+0FOq8Ys0r8s6BTuCphp0+CII+CQQ1i6FJ56ylrBjz8+0QVzLm/zwCynHXQQ9O1LqU/HM75mX94duZXk5EQXyhVov/wCFSpA9+6wcWP25TtnjtWWSczK7gO1bg2LFtlcmNGWL7d13oxZMKlax/+gGbN/f1v80EMJLJNz+YQHZrnhnnvg5ps5569n+HzVMcwZ/FmiS+QKsokTYe9eGDcOjjnGhrfIqj17YN68jA1rERlo9vvvD1w3ebLde2BWMP32G6xfD23bMmeOTX95yy1QK/+NSulcrvPALDeUKgXDh5M0+Rt2Fy1D8/s6Qq9e2Vub4VzElCnWhPT99zbW2FlnwbXX2lWVmbVggQV78fQvi2je3JopYzVnTpkCFSvCccdlvkwu74r0L2vbljvvtI/6rgNmWXbOxeKBWS4q3q4Nz18zh0eK3IuOGgWNG8O77ya6WK4gSU6GqVNtCIoTTrDhCv7v/+CFF6xzzzffZC7f2bPtPiOBWZkyts1YgdnkydCunY+ZUFBNmwaVKjHonSP53/+sKbNChUQXyrn8wc+KueyyPqW4J2UQb//fTKheHbp2tXnkNsQzHq9z6fjxR/j7731NhKVKwaOPwldfWb+fU06xWSl27047n2hz5lh/yQYNMva6E0+EH35gv46VS5fCn396M2ZBNm0avx/Shv4PFOGyy+DGGxNdIOfyDw/MclmTJlaJ8NikJtbU9Mgj8OGH8MADiS6aKwgifbeiB209+WT46Se7SvjRR+HKKzOW75w5dvBmtIbrxBNh+3brnxZdRg/MCqb16+HXX3n5l7b07GnjN/qFt87FzwOzBLjySmthmvdrcet4cfrpNtmvc1k1ZQoceSRUq3bgunLl4PnnLTibMMH6jMUjOdlq4jLSjBkRuQAg3Jw5ZYoNu3H00RnPz+V5791hn3XpDm0ZOdKDMucyygOzBOjZE4oXD80E0K4dLFwIa9YktFwun0tK2te/LC1nnmm1WD/8EF++ixZZ+swEZvXqQdWq+wIzVe9fVoANGwa/vTqNpCLFuff95j4FqnOZ4GfGBKhSxeY4HzUqqLSI/JBOnZrIYrn8bs4c2Lo1/SbC9u1tLLJ4a2kjI/5nZKiMiMhAs9On2/M//4S//vJmzALoySfhttugU5VpFG3RdbbxOwAAIABJREFUjGLlSie6SM7lSx6YJciVV8LatTbkFCecAGXL7ps70LnMiBw/7dqlna5yZesvlpHArEQJu4o4M0480ca12rDB+5cVUCNG2Dhll1ywm0ZbZyAntU3/Rc65mDwwS5COHeGww4LmzOLF4aST7Mo55zJr8mRo1MgOrPScdpqNzB7P1E2zZ9tAtcWLZ65ckQnNp0+34PGQQ+CoozKXl8tzRo+2qy47d4ZRt81Gdu/+Z8R/51zGeWCWIMWKwWWXwccfW80Z7drB/Pmxp69xLj1JSfD11/HXRHXoYKP5f/tt2ulU903FlFktWuwbaHby5H1Nqa5AGDLEDo+xY6HY98HAsm3aJLZQzuVjHpgl0JVX2u/pqFF4PzOXNbNm2cj+6XX8jzjpJPt3kF5z5vLl1gSZmf5lEWXL2gj/Y8bAihXejFmAzJ8PP/9s57ISJbCBZQ8/HA49NNFFcy7f8sAsgY46Clq1suZMbdbcRkr3fmYuMyLHTbyBWbly0LIlfPFF2ukyM+J/LK1bw+LF9jgfB2Yi0lFEfhWRRSJywCRDIjJMRH4Mbr+JyOZElDO3jBljF9defDFWuzptmjdjOpdFHpgl2JVX2tibs+cWtxOa9zNzmTF5snXOP+SQ+F/ToYMNqPf336mnmTPHmh2zOqdlZDyzww6Dhg2zlleCiEhR4GngLKAx0F1E9rsiQlVvVdUmqtoE+C/wXu6XNHeoWmDWoUNQQbZokXXF8MDMuSzxwCzBunWD0qVhwADQU9rB3Lk2crZz8dq71+bAzGhN1GmnQUpK2s3nc+bYgLVly2atjJHA7NRT83P/spbAIlVdrKp7gLFApzTSdwfG5ErJEmDGDKsE7d49WBCauNw5l3kemCVY+fIweDB89BG8vba9Lfz664SWyeUzM2faALDxNmNGtG5tc2mm1Zw5Z07W+pdFHH443HCD3fKvGsCy0PPlwbIDiEgdoB5QYKf0GD3a+pV17hws+PZbm6ncr7h1Lks8MMsDbrwROnWCq55tQXLJ0t7PzGVMvOOXRStVymo3UrsAYP16WLYs6/3LwGrJRowoTLUp3YBxqpoca6WIXC0iM0Vk5rp8eCV2cjK89Racc47FYoDVmLVp4zM6OJdF/g3KA0TglVegSvUSTC/ShuQvpiS6SC4/mTzZxhmrWjXjr+3QwZrP1649cF1kxP/sCMwKhhVArdDzmsGyWLqRRjOmqr6gqs1VtXnVzHxuCfbVV7B6dagZc+NGWLCgMAXezuUYD8zyiEqVrCPtZ7vaI/Pnohs2pv8iVXjzTRvOwBVOe/ZYTUVGmzEjTjvN7iMj8od5YBZtBnCEiNQTkRJY8DUhOpGINAIqAt9FrysoRo+Ggw6Cc88NFkTmQvXAzLks88AsD2nTBhr2aUcRlM/vi2M8s88+g0svtREeXeE0Y4aN3p/ZISiaNYODD47dnDlnDtSpY/8aHKqaBPQFPgMWAm+r6nwReVBEzg8l7QaMVVVNRDlz2u7d8O671resdGQ6zGnTbFy8Fi0SWjbnCgIPzPKYHsNbsrtIKX578St+/jmNhKowcKA9fucde+4Kn0j/slNOydzrixWzvmmxArPZs722LIqqTlTVhqp6uKo+HCy7X1UnhNIMUNUDxjgrKD77DDZvDjVjggVmJ5xgYzE657IkrsAsjkEVS4rIW8H670WkbrC8sohMFpFtIjIi6jXNRGRu8JqnROwaehGpJP/f3p3H2VzvDxx/vY19F3KFkKXSppJok6KIUGTJDeXm1k3ai6RcpW7162q9ddssyZVoQW67tNt3smQmkSRpvbbh/fvj/R2OMcuZMXO+58x5Px+P8zjnfM/3+z3vc8x8veezvD8i74nImuC+yqF/zMRRrEwppGVLzpWP6NHDirln6YMPbO3Bs8+GtDRrOXHJZ+ZMqzFWrVr+z3HeeVaDav36/dt+/x3WrPHEzB1kwgSoWhXatAk27NoFc+Z4N6ZzBSTXxCyaoopAf2CbqjYERgEZfWs7gGHArVmc+mngaqBRcGsXbB8MfKCqjYAPgudJpeQF53L8nsVs/mobAwdmsUNGa1mtWtZaVqIETJoU8zhdyHbutBIF+R1fliFjnFlkq9nixfZzVhClMlyR8fvvMHWqVfrft6b9woWwY4cnZs4VkGhazKIpqtgZGBs8ngycLyKiqn+o6qdYgraPiNQEKqrql8E4jHFAlyzONTZie/Jo1QpR5ckenzB2LIwbl+n1jz6ygqKDB1vJ7QsvtMRs794wonVhmTsXtm8/9CWOMmZ0RiZmBbUUkytSpk61H7kDujEzJo54YuZcgYgmMYumqOK+fYIBsr8AVXM554ZszllDVTcFj78Hkm813NNPh1Kl6FlzFq1aWU3OAyZejhgBNWvCX/5iz3v0sHpTs2eHEq4LycyZVmslv+PLMhQrZsndBx/sH6u4cKEla0cccehxuiJjwgSoXTvIwdLTbcmSoUPtmvWnP4UdnnNFQlwP/g9a07Ic1Z7oBRpzVLo0tGxJsY8/4sknrfvgiSeC1z7+2FrMbr/d9gPo1AlKlfLuzGTz0Udw0kkFM2vyvPPgu+9g9Wp7vnChtZYl7vJJroBt3WoD/3v1gmLfpNqkkb//3WaGv/tu2OE5V2REk5hFU1Rx3z4iUhyoBORUXGtjcJ6szrk56OrM6PLMovJl4hdozFWrVrBoEcfX/pnOneHxx+G334B777WFqgcM2L9vxYrQrp2NN/PuzORQUOPLMkSOM9u5E5Yv9/Fl7gBTplgj2d8qvQxNm8KyZVZ8cexYuwY55wpENIlZNEUVpwJ9g8fdgA9zquETdFX+KiItgtmYfYA3szhX34jtyeXccy3J+vRThgyBbdtg+p2fw/vvw223HTwtvUcP2LjR/rN2ieG556y1q3VruOMO+5/v22+jK30ye7YNuC6oxKxhQ6hTx7ozly+3hdF9fJmL8Oa4X3izwp+pd9ef4YQTbIJIz55hh+VckVM8tx1UNV1EMooqpgAvZhRVBOYF9XteAF4SkbXAT1jyBoCIpAEVgZIi0gW4QFVXAH8DxgBlgP8GN4B/AJNEpD/wDdC9ID5owjn9dFsheNYsTn+4I+edBzWeuxetVg255pqD9+/Y0bo2J02Cs86Kfbwu7555xhLsP/6AUaMsGQIbq9O8OTRrBuXKWTmC3bvtPuO2YEHBjC/LIGKtZtOm2WQS8MTM7fPDm1/w5GeXU7fYt9Z9eeedVgPPOVfgovrNUtUZwIxM2+6OeLwDuCybY+tls30ecHwW27cC50cTV5FWpgy0aLGvgOg/Lp3DaR++zez2D3B6+fIH71+hAlx0kXVnjhoFKSmxjdflzdq1llw98gjcfLN1Hy5ebPWg5syxGZdTMzVMi1iynnHr0QOqFGCZv/POs26psWPt56lBg4I7t0tcW7ZQ5bLz+Z0/sfE/n1Cne8uwI3KuSPM/eeJZq1YwciT88gvN3r6XX1IO4y8Lr2NhejZ/rHbvDq+9ZqU0WrWKebguD1591e67dbP7UqWslax58/37/PEH7NljSViJEoWfbGeMM/vsMytcXCyu5wa5WHn5ZUrs3s7gJtOY1P24sKNxrsjzK288yxhn9sQTyPTpfNfjJpZ9UyH7yZcdO1pLm8/OjH+TJkHLlnDkkdnvU66cDaouXTo2LaC1a0PjxvbYuzFdYOe/xzCH0zj9Kk/KnIsFT8ziWYsW1lJyzz1QqRJHP3k9TZrAAw9kM/myXDlLziZPtpYWF59Wr4ZFi6yFM95ktJp5YuYAFi2i1FeLGUs/evQIOxjnkoMnZvGsbFmbBLB3L9x4I8WqVGLIEJulPn16Nsd07w4//ACzZsU0VJcHmbsx40mnTtY6d8YZYUfi4oC+OJpdUpK0lr2oXTv3/Z1zh84Ts3jXsaNVYL/hBsBmp9erB/ffn01VhYsuspYz786MX5MmWen0ePyfrn17+P77/V2aLnnt2sWel17mde1CxysKcJKJcy5HnpjFu9tug7S0fbPvihe3klezZ++bsHmgsmXh4ov3V4N08eWrr2DJkvjsxsxQrVrYEbh48NZbFP95Ky8V6xeXjbvOFVWemMW7YsUOKibbr5+Vurr//myO6d4dfvxx/+LCLn68+qqVvejaNexInMuRjh7N9ylHoG0voCguruJcvPLELAGVLm2lr95/30peHaR9eyhf3rsz41FGAeBatcKOxLnsbd4MM2YwZs8VdO/lNRGdiyVPzBLUNddA5co2Q/MgpUtD585W0yyjmrwL34oVNnMjnrsxnQN4+WVkzx4mlOhHly5hB+NccvHELEFVqACDBsEbb9jShgfp3h1++snWPnTxwbsxXSJQRUePZl6JFjTseAyVKoUdkHPJxROzBDZokCVot9+exYsXXmjFSSdOjHlcLhuTJtnaljVrhh2Jc9lbsABZtozndvejV6+wg3Eu+XhilsCqVoXhw2HGjCzqmpUqZbU1xo2Df/4zm9oaLmaWL7euTO/GdPFu9Gh2p5TirXI96NAh7GCcSz6emCW466+HY4+1Mmc7dmR68dFH4dJL4ZZb4MYbfTWAME2aZDNsL7007Eicy97OneiECUwtdgnndqmceUK4cy4GPDFLcCVKwOOPw7p18MgjmV7MWDfz5pttp27d4H//CyXOpKZq/w6tWlmdE+fi1bRpyLZt/Hv3ld6N6VxIPDErAtq0sYaYkSNh/fpMLxYrZhnbY4/Bm2/aWohbtoQSZ9JatswKy3o3pot3o0fzU5laLKh8Pm3bhh2Mc8nJE7MiImMY2a23ZrPDoEG2GsDixdCyJaxZE9P4kpp3Y7pEsGkT+vbbvJDeh0svS6FkybADci45eWJWRNStC0OGWEWGDz/MZqdLLrHVAH75xZKzL76IaYxJKaMbs3VrOPzwsKNxLnvjxyN79/Lc7n707Bl2MM4lL0/MipDbbrMFzgcNyqGubIsWlpBVqWLdmu++G8sQk8+SJbB6tXdjuvimCqNH89VhZ/B7zca0ahV2QM4lL0/MipAyZWDUKKvM8K9/5bBjw4aWnB19tLWiff55zGJMOpMmQUqKfc/Oxau5c2HlSh7/tR/du9uPrHMuHJ6YFTGdO8MFF8Ddd9tyd9mqVg3eecfWbOzQwVp2XNbmz7eWxbzMaP36a3joIXjuOWuZ9FWgXTwbM4b0EqV5Ob27d2M6FzJPzIoYEauMsX27jTnLUY0a8N57tuD5BRf4hIDM9uyxDPe002wlhYzu3/vvt9XjM9eF++oruO8+OPlka5W84w7rWx45MpTwXcETkXYiskpE1orI4Gz26S4iK0RkuYhMiHWMebZzJ0ycyCdVL+GwepU4/fSwA3IuuXliVgQdfbTVkx09GmbPzmXnunUtOduzB9q2hQ0bYhJj3Nu82ZKxe++Ffv3gv/+1wXvbtsHQoXD66dbq2LWrrYl1/PFW6XfYMChb1qbJpqVZAnfaaWF/GlcARCQFeApoDzQBeolIk0z7NAKGAGeq6nHAjTEPNK+mT4dt23j4h7707Gl/3DnnwiNaBJbqadasmc6bNy/sMOLKb79ZglapkuUU9erlcsD8+TZzsHZt+PhjSzqS1ccf23JW27bZYL0rrzzw9S1bbHH499+3pHbDBlsDs2tXG0tWq1Y4cScZEZmvqs1i+H4tgeGqemHwfAiAqj4Qsc9DwGpVfT7a84Z+/ercmT9mzaXiL9+ycHEKJ54YXijOJYucrl/eYlZEVagA48fDpk3QrFkOJTQynHqq/eWcmgrt2sGvv8YkzoPs3RvO+2a894MPWndl+fLW3Jg5KQMbL9azJzz/vLWK/fGHlSEZONCTsqKtFvBtxPMNwbZIjYHGIvKZiHwpIu1iFl1+bNkCM2bw38P+TP0GKZxwQtgBOeeiSsxyG1chIqVE5JXg9dkiUi/itSHB9lUikvGX5tEisiji9quI3Bi8NlxENka8dlHBfNTkc955NtmqRg3rpRw1Kpe1zM85ByZPtiK0nTrZQLVY2b3buv8OO8zGcMXaTz/ZzInBg60Q7Lx5RNV0IAKlSxd+fC5RFAcaAecCvYDnRKRy5p1EZICIzBOReVvCXInjP/+B9HTu39CHiy/2bkzn4kGuiVk04yqA/sA2VW0IjAIeDI5tAvQEjgPaAf8SkRRVXaWqTVW1KXAq8D/g9Yjzjcp4XVVnHNpHTG6NGsGXX1rOcfPNcMUVuUwu7NABxo2z7rzLLoNduwo/yPffh5NOssXWy5aFe+6BhQsL/30zLFliLYbvvANPPAGvvAIVK8bu/V2i2AjUiXheO9gWaQMwVVV3q2oqsBpL1A6gqs+qajNVbVY9zBm7Y8fyc4NTWLj7eDp0CC8M59x+0bSYNQfWquo6Vd0FTAQ6Z9qnMzA2eDwZOF9EJNg+UVV3BheptcH5Ip0PfK2q3+T3Q7icVahgDWH33QcTJsBZZ8E3OX3bvXrB00/DW29B796Qnl44gX3zjS2s3ratJYDTplkRturVbcB9LJLCd96xL2T3bvj0U+uO9GYDl7W5QCMRqS8iJbE/Oqdm2ucNrLUMEamGdW2ui2WQUVu2DBYs4J3D+1C+vDWYO+fCF01iFs24in37qGo68AtQNcpjewL/ybRtoIgsEZEXRaRKFDG6XBQrZpMJp02zElunnprLuLO//tW6FidPhquuKtixX9u3w4gRNotxxgzLGJctg44drSTFs89aK9Z99xXce2blueeshfCoo6xZsXnmvxmc2y+4tg0E3gFWApNUdbmIjBCRTsFu7wBbRWQFMBO4TVW3hhNxLsaNQ4sXZ+S6Xlx4Ib42pnNxItTB/8FfnZ2AVyM2Pw00AJoCm4BHsjk2PsZoJJgOHWzc2eGHW+myAQNyaD276SYrF/HSS/C3v+UyQC1KM2fCccdZd2XHjlb7a+jQA8dpdewIffrYWLMFCw79PTPbuxfuvNM+fNu28MknNhvVuVyo6gxVbayqDVR1ZLDtblWdGjxWVb1ZVZuo6gmqOjHciLOxZw+MH8+vZ7Rn6ebD6dgx7ICccxmiScyiGVexbx8RKQ5UArZGcWx7YIGq7qtRr6qbVXWPqu4FnuPgrs+M/eJjjEYCatzYGoiuvRbGjrVxaNdeC99+m8XOQ4dapdp//9sGqeU3Odu71xKtNm2gRAkrNzFpEhx5ZNb7P/qoZY9XXlmwXZo7dlj37AMPWGI2bZr19TqXTD74ADZt4t2afRGB9u3DDsg5lyGaxCyacRVTgb7B427Ah2oF0qYCPYNZm/WxQbBzIo7rRaZuTBGpGfH0EmBZtB/GRa9iRRvnvnYt9O8PL7xgxeoHDoSNkamziFWuHzTIkqVhw/L+Zlu3wsUXW5LXvbvVTDvvvJyPKYwuza1brYVs4kQri/HMM1C8eMGc27lEMnYsVKnC4+s60ry5zdx2zsUJVc31BlyEzS76GhgabBsBdAoel8a6I9diiddREccODY5bBbSP2F4Oa1WrlOm9XgKWAkuwxK5mbvGdeuqp6g5NWprqgAGqxYurliqlOmiQ6qZNETvs3at69dWqoDpyZPQnnj1b9cgjVUuUUH3qKTtPXvTpo5qSojp/ft6Oy2zVKtVGjezDvfLKoZ3LxQVgnkZx/Yr3W8yvX7/8olqmjP7R91oVUR0xIrZv75zL+foV+kWpIG6emBWcdetU+/e3XOjwwy2v2ic9XbV3b/uxefhh1e3bsz/R3r2qTz5pCVnduqpz5uQvoJ9+Uq1ZU/WEE1R37sz78evXq/71r5ZxVq2q+umn+YvDxR1PzPLphRdUQafd9aWC6oIFsX1751zO1y+v/O8OUL++FbRfvBjKlYNWrWDKlODFlBQYM8YKsN52m+3QuDF06WLj0F56ybopN2+Gyy+3ftELLrAB/PldLzKjS3Pp0rx1aX73nb1/w4bw4os2y3TJEjjzzPzF4VxRMW4cNG7MmBXNOeIIaNo07ICcc5F8gI3L0nHH2QSBLl2s1NiDD1ouJsWL2xitN9+0ZGnFCli50spe7N69/wTFitkA+9tvt8eHInKWZpcucMop2e/7/fcW7NNP28yz/v1tBmZ2kwycSyapqTBrFukjRvLuw0KvXl62z7l444mZy9bhh1uts3794I47YM0aW9O7RIkSlq1167Z/5927rUDaihWwapU1tZ1xRsEF8+ijtmB4xkLrFSrYDIbI+x07bIHQXbugb1+46y5rAnTOmfHjQYQvG/yZ337Dy2Q4F4c8MXM5Kl3aVgto2NAmZ6amWs3ZyplX/ytRAo45xm6FoUoVmDrVWsJ+/dVuv/1mXZYZj3fssFmfw4ZZwM65/VStG7N1a6bMPZLSpeH888MOyjmXmSdmLlfFitnwroYNrfTXGWfYak0xb4xq1szqejjn8u6LL2DtWnToXUy7zyrWlC0bdlDOucx88L+LWr9+8O67Nozr9NOtx9I5lyDGjoWyZVlzYle+/hpftNy5OOWJmcuTc8+Fzz+3xx06wI8/hhqOcy4au3bZShuXXsq0meUBT8yci1eemLk8O+YYm5S5YYNVzti5M+yInHM5+vBD+Pln6NGDt96CE06AunXDDso5lxVPzFy+tGxpPSOffAJXX10w65s75wrJlClQoQI/n9aWTz7x2ZjOxTMf/O/yrUcPK6ExbJjVmb3rrrAjcs4dJD0dXn8dLr6Yd2eVIj3dEzPn4pknZu6QDB0Kq1fvr1DRs2fYETnnDvDxx7B1K3TrxvTXoWpVm7zjnItP3pXpDokIPPccnH22zdr84ouwI3LOHWDyZChblj1tLmTGDGjf3lZXc87FJ0/M3CErVcp6SurUgc6drQitcy4O7Nljv5wXXcScZWXZutW7MZ2Ld56YuQJRtSpMn27DWTp0sAlgzrmQff65FR7s1o3p062l7MILww7KOZcTT8xcgTn6aHjtNZsQ0LAhDBoE8+f7jE3nQjNlijVpX3QRb71lQw4OWk7NORdXPDFzBercc+Gjj6BNG3j2WVtF6cQT4ZFH7A9351yM7N1riVm7duwsWYGlSy0xc87FN0/MXIE780yYOBE2bbI1x8uXh1tvhdq1bXzL9OlhR+hcEpg716pAd+3KqlWWpx13XNhBOedy44mZKzRVqsA119hMzZUr4bbbYNEiuPhiGDMm7OicK+ImT4YSJeDii1mxwjY1aRJuSM653Hli5mLimGPggQdsxub558OAAdbl6ZwrBKqWmLVpA5Urs2KFDfxv3DjswJxzufHEzMVUiRL2/0WDBrbO5urVYUfkXBG0cCGkpUG3bgAsX24TckqVCjcs51zuPDFzMVe5Mrz1lv0F36GDFSV3zhWgyZPtF6xzZwBWrPBuTOcShSdmLhRHHQVvvAHr11vL2a5dYUfkXBGR0Y3ZujVUrcquXVbCxgf+O5cYPDFzoTnzTBg92pbyGzDA6505VyCWLbNMrGtXwIYL7NnjLWbOJYqoEjMRaSciq0RkrYgMzuL1UiLySvD6bBGpF/HakGD7KhG5MGJ7mogsFZFFIjIvYvthIvKeiKwJ7qsc2kd08ezyy2H4cBg71iYHOOcO0ZQptojtJZcA+IxM5xJMromZiKQATwHtgSZALxHJ/CveH9imqg2BUcCDwbFNgJ7AcUA74F/B+TK0VtWmqtosYttg4ANVbQR8EDx3Rdjdd1uCNnQoTJoUdjTOJbjJk62SbI0agCVmxYrZyhzOufgXTYtZc2Ctqq5T1V3ARKBzpn06A2ODx5OB80VEgu0TVXWnqqYCa4Pz5STyXGOBLlHE6BKYCLzwgnVt9ukDn34adkTOZS2K3oN+IrIl6AlYJCJ/iWmAX31lUzCD2ZhgTxs0gNKlYxqJcy6foknMagHfRjzfEGzLch9VTQd+AarmcqwC74rIfBEZELFPDVXdFDz+HqgRRYwuwZUuDa+/DnXrwgUXwIwZYUfk3IGi7D0AeCXoCWiqqs/HNMgpU+z+0kv3bfIZmc4lljAH/5+lqqdgF7nrROSczDuoqmIJ3EFEZICIzBOReVu2bCnkUF0sVK8On3wCxx5rs/zHjw87IucOEE3vQbimTIGWLaGW/f27e7cN/vcZmc4ljmgSs41AnYjntYNtWe4jIsWBSsDWnI5V1Yz7H4DX2d/FuVlEagbnqgn8kFVQqvqsqjZT1WbVq1eP4mO4RHD44TBzJpxzDlxxBTz6aNgRObdPNL0HAF1FZImITBaROlm8XjjWrbPCssFsTLDJmenp3mLmXCKJJjGbCzQSkfoiUhIbzD810z5Tgb7B427Ah0Fr11SgZzBrsz7QCJgjIuVEpAKAiJQDLgCWZXGuvsCb+ftoLlFVrGhdmV27wk03wZ13eikNlzCmAfVU9UTgPfaPlz1AobT4z5pl9x067NvkMzKdSzy5JmbBmLGBwDvASmCSqi4XkREi0inY7QWgqoisBW4mmEmpqsuBScAK4G3gOlXdg40b+1REFgNzgLdU9e3gXP8A2orIGqBN8NwlmVKl4JVX4K9/tTIaAwbYX/7OhSjX3gNV3aqqO4OnzwOnZnWiQmnxX7fOpl82aLBv04oVNrnmmGMK5i2cc4WveDQ7qeoMYEambXdHPN4BXJbNsSOBkZm2rQNOymb/rcD50cTliraUFHj6aevevPdeW7ppwgSfXeZCs6/3AEvIegKXR+4gIjUjJi91wv6YjY3UVKhd2xakDSxfbqtslCkTsyicc4coqsTMubCIwIgRNjFg0CBo0wZeftlmbzoXS6qaLiIZvQcpwIsZvQfAPFWdCgwKehLSgZ+AfjELMC0N6tc/YJPPyHQu8fiSTC4hXH89TJwIixfDCSfAiy/6uDMXe6o6Q1Ubq2qDoDcAVb07SMpQ1SGqepyqnqSqrVX1q5gFl5p6QGKWng6rVnli5lyi8cTMJYwePWDpUjj1VOjfHzp1gk2bcj/OuSJvxw747juoV2/fprVrrVyGl8pwLrF4YuYSSr168MEHVkbj/ffh+ON9GSfnWL/e7iNazHxGpnOJyRMzl3CKFYMbbrDWsktpAAAUnklEQVSSTQ0bWktar142OcC5pJSaavdZJGY+I9O5xOKJmUtYxxwDn30G991nBc+PP94WRJ87F/buDTs652Ioi8Rs+XJ7Wq5cSDE55/LFEzOX0IoXh6FDYc4cS9RGjoTmzW1FmquvhqlT4Y8/wo7SuUKWmmplMmrW3LfJZ2Q6l5g8MXNFQtOmtpTT5s0wbhycfbYVqO3cGapVs2Lob7+d+3mcS0hpaVZDJiUF8BmZziUyT8xckVKtmq2xOWkS/PgjvPeerRqwdKklaQsWhB2hc4UgU6mMdetg506fkelcIvLEzBVZJUtaQdrHHrOErHp16NkTfvst7MicK2CZEjOfkelc4vLEzCWFatVsxYCvv4aBA8OOxrkC9Pvv1jwcUcMsIzE79thwQnLO5Z8nZi5ptGoFw4bZGLSXXgo7GucKSFqa3WeakVm3LpQvH05Izrn888TMJZW77rKJAddeC6tXhx2NcwUgmxpm3o3pXGLyxMwlleLFrUuzVCkbb7ZzZ9gROXeIMiVme/bAV195YuZcovLEzCWdOnVg9GhbOWDw4LCjce4QpaZC2bI2uyV4umOHJ2bOJSpPzFxS6tQJrr/e1tycPj3saJw7BGlpNvBfBNg/8N9LZTiXmDwxc0nroYesMG2/frBxY9jROJdPmUplLF9u9z4j07nE5ImZS1qlS8PEidbt07u3VUt3LqGoWmKWqVRG7dpQsWJ4YTnn8s8TM5fUjj4annoKZs2Ciy6CbdsK7tyrVsEll8DrrxfcOZ07wM8/w6+/HjQj07sxnUtcnpi5pNe3L7zwAnz0kS2AvnLloZ0vPd26SU86Cd54A+6+2xo2nCtwmWZk7t1rP78+8N+5xOWJmXPAVVfZIui//gotWsCMGfk7z/LlcMYZcMcd1gI3fDgsW2YzQJ0rcJkSs7Q02L7dEzPnEpknZs4FzjwT5s6FBg2gY0d4+OHoW7p274b774dTTrH/KydOhClTYNAgq5k2enThxu6SVEZiFowx8xmZziU+T8yci3DkkfDpp3DZZXD77dCnj00OyMmSJdbKNnQodOli/zn26GHVC6pUsW0TJngxW1cI0tKgUiX7QcNnZDpXFBQPOwDn4k3ZstbideKJtoTT6tVWiPbHH2Hz5oNvX38Nhx0GkydD164Hn69fP3jlFauXltXr2dm5E0qW3FeeyrmDZSqVsWIFHHEEVK4cYkzOuUMSVYuZiLQTkVUislZEDqqVLiKlROSV4PXZIlIv4rUhwfZVInJhsK2OiMwUkRUislxEbojYf7iIbBSRRcHtokP/mM7ljYi1gL3+urVCXHopDBhgi6CPH2+tZGDJ26232n+I2SVdbdvaf5Z56c785hs4/HAYM+aQP4oryrJIzLwb07nElmuLmYikAE8BbYENwFwRmaqqKyJ26w9sU9WGItITeBDoISJNgJ7AccARwPsi0hhIB25R1QUiUgGYLyLvRZxzlKr+X0F9SOfyq0sXWLPGCtDWqGHJUqlSeTtHSop1iT78MGzaBDVr5n7M8OE2EeHZZ+HKK/MVuivqVK0rs107wGZkrlgBV18dbljOuUMTTYtZc2Ctqq5T1V3ARKBzpn06A2ODx5OB80VEgu0TVXWnqqYCa4HmqrpJVRcAqOpvwEqg1qF/HOcKXs2a0KyZrbGZ16QsQ79+trj0yy/nvu+KFTBunLWyffmldZU6d5AffrApmEGL2fr18L//+YxM5xJdNIlZLeDbiOcbODiJ2rePqqYDvwBVozk26PY8GZgdsXmgiCwRkRdFpEoUMToX144+Glq2tO7M3GZ63nUXlC+/fw3PCRMKPz6XgDKVypgdXEG9K9O5xBbqrEwRKQ9MAW5U1V+DzU8DDYCmwCbgkWyOHSAi80Rk3pYtW2ISr3OHol8/aw2bNy/7fWbPtnFtt94KJ58M55xjrWxeoNYdJCIx++47uOEGaNwYTj013LCcc4cmmsRsI1An4nntYFuW+4hIcaASsDWnY0WkBJaUvayqr2XsoKqbVXWPqu4FnsO6Ug+iqs+qajNVbVa9evUoPoZz4erRw9bnzG5Av6rN/qxeHW66ybb17m1LOy1YELMwXaJISwNgV826XHYZ/P47vPaa/Yw55xJXNInZXKCRiNQXkZLYYP6pmfaZCvQNHncDPlRVDbb3DGZt1gcaAXOC8WcvACtV9Z+RJxKRyKHRlwDL8vqhnItHlSrZ7M4JE7Kujfbee7Ys1LBh1pUJ0K0blCgR3dg0l2RSU6F6dW4dXp7PP7dlxbwb07nEl2tiFowZGwi8gw3Sn6Sqy0VkhIh0CnZ7AagqImuBm4HBwbHLgUnACuBt4DpV3QOcCVwBnJdFWYyHRGSpiCwBWgM3FdSHdS5sV15p605PzfSnzd69cOedVsB9wID92w87zJZ2mjjRJg84t09qKj9WrM8TT1gLa48eYQfknCsIURWYVdUZwIxM2+6OeLwDuCybY0cCIzNt+xTIsmymql4RTUzOJaLWrW1255gx0L37/u1TpsD8+TB27MEzP3v3hjfftLU827SJabguExFpBzwGpADPq+o/stmvKzZD/TRVzWFUYf7tXJXKzO+acfbZ8OCDhfEOzrkw+JJMzsVQRk2zd96x2mhg62wOHWrdUL17H3xMx45QoYJ3Z4YtoqZje6AJ0Cuo1Zh5vwrADRw407xA/bx1D/LtejaXrsekSdbd7ZwrGjwxcy7G+vWzrsvx4+35mDFWxPb++y1xy6xMGVtVYMoUK1vlQhNNTUeAe7Ei27msspo/e/fCzT2/oyS7aXdtff70p8J4F+dcWDwxcy7GGjaEs86yhGz7dqvy37IlXHxx9sf07g2//ba/tpkLRTR1GU8B6qjqW4UVxAMPwNr3rVRGw7b1c9nbOZdoPDFzLgRXXglffQV9+8J339l/tjktVt66ta1A4N2Z8UtEigH/BG6JYt981WF8912btXt5i6CGWb16+QvWORe3PDFzLgSXXQZly8Krr9pSh61a5bx/Sgr07AkzZsBPP8UmRneQ3Go6VgCOBz4SkTSgBTBVRJplPlF+6jDu3Qs33mhjEa86L80y+bp18/lRnHPxyhMz50JQoYKNGwMbWxaN3r1tosDkyYUX14wZULEiLCuE6oHffgu7dhX8eWMox5qOqvqLqlZT1XqqWg/4EuhUULMyixWzWndvvAElN6baYqr5XbzVORe3PDFzLiQPP2yzM08+Obr9TznF1twsrO7M9HS45RYbyzZ8eMGe+7vvLPbbby/Y88ZSlDUdC1WtWtCgAVZctr6PL3OuKPLEzLmQ1KgBF1wQ/f4i1mr28cewfn3BxzNmjI17O+ssmwG6aFHBnXvUKJvo8MwzlqQlKlWdoaqNVbVBUKMRVb1bVTOvhoKqnltYNcxIS/PxZc4VUZ6YOZdALr/c7v/zn4I97//+B/fcY7NDp0615aP+/veCOfe2bZaQtWplrXIPPVQw501au3fDhg3eYuZcEeWJmXMJpEEDaNGi4LszH3/cWrIefBCqVIGbb7axTAWxePrTT9sC2489BldcAf/+N3z//aGfN2mtX28zATwxc65I8sTMuQTTuzcsXWq3grB1K/zjH1ZH7eyzbdsNN0Dlyoc+1mz7dnj0UZt5etJJtsLB7t02vs7lU2pQKsMTM+eKJE/MnEsw3btb+YyCajV74AEb8B85O7RSJZsIMG0azDuEUVJjxsCWLTB4sD1v2NASy6efhs2bDyns5JWWZvc+xsy5IskTM+cSzOGHWwvUk0/CSy+Bav7P9c038MQTVuj2+OMPfG3QIDjssPy3mqWnW8tYixZwzjn7tw8dCjt3wiOP5Dvs5Jaaapl57dphR+KcKwSemDmXgJ55xspn9OljEwJ+/jl/57nnHpvtmdVA/4oV4dZb4a23YHY+luOePNlyiDvuOHBVg8aNoVcveOopa01zeZSaCkceCcWLhx2Jc64QeGLmXAKqXRtmzoSRIy0BOvFEmDUrb+dYuhTGjbOWsTp1st5n4ECoVi3vrWaqNm7tmGOgUxYVvu66y8af/fOfeTuvw2uYOVfEeWLmXIJKSYE774TPPrMC8K1b7x9cH40hQ2wsWcb4r6xUqAC33QZvvw1ffBF9bO+8A4sXW2tZsSyuMsccAz16WHfs1q3Rn9fhNcycK+I8MXMuwTVvDgsXwlVX2QD+M86ANWtyPmbWLOuiHDLExpHl5LrroHp16/aM1oMPWqteRt21rAwbBn/84a1mebJ9u9Ua8RYz54osT8ycKwLKl4fnn7duza+/ttIUHTtaV+cHH9isywyq1pJVqxZcf33u5y5XzvZ/7z349NPc9589Gz76yGqhlSyZ/X5Nmthi7k884QuzRy1jRqYnZs4VWZ6YOVeEdO0KS5ZYIdd162wsV5s21mV54okwYICtVzl7NowYAWXKRHfea6+1JaSiaTXLKFJ79dW573vXXZY0PvpodHEkvYwaZt6V6VyR5YmZc0VM7dpWXX/FClsO6e23LaGqVQtefRX+7//guONsRme0ypa1VrMPP4TXX7fC81lZudJeHzjQWvFyc8IJlkw+9pjF6nLhLWbOFXmemDlXhFWuDBdeaInZf/9rA+1XrrSuxrxWW7jmGqvScOmlULMm/PnPMHbsgYuSP/ywtcJF00WaYdgw+PVXWxbK5SI11WZ6/OlPYUfinCsknpg5l0SKFbMZkdWq5f3YMmVg/nxLxtq2tTFn/fpZS9zxx1vZjfHjoX9/mywQrZNOgi5drDvz99/zHldSSU21bsyspro654oEr1DonItatWrWBdqnj3VnLlliCdq778Kzz1q+cMsteT/v/fdba1403Z9JzUtlOFfkRfVnl4i0E5FVIrJWRA6qeiQipUTkleD12SJSL+K1IcH2VSJyYW7nFJH6wTnWBufMYV6Xcy4sxYpB06ZW5+y992yM2Lp1+csbjj0WzjqrwEMsel591WdKOFfE5ZqYiUgK8BTQHmgC9BKRJpl26w9sU9WGwCjgweDYJkBP4DigHfAvEUnJ5ZwPAqOCc20Lzu2ci3NlysARR4QdRRFXv771RTvniqxoWsyaA2tVdZ2q7gImAp0z7dMZGBs8ngycLyISbJ+oqjtVNRVYG5wvy3MGx5wXnIPgnF3y//Gcc8455xJHNIlZLeDbiOcbgm1Z7qOq6cAvQNUcjs1ue1Xg5+Ac2b2Xc84551yRlLBTe0RkgIjME5F5W7ZsCTsc55xzzrlDFk1ithGoE/G8drAty31EpDhQCdiaw7HZbd8KVA7Okd17AaCqz6pqM1VtVj0vc/Odc8455+JUNInZXKBRMFuyJDaYf2qmfaYCfYPH3YAPVVWD7T2DWZv1gUbAnOzOGRwzMzgHwTnfzP/Hc84555xLHLnWMVPVdBEZCLwDpAAvqupyERkBzFPVqcALwEsishb4CUu0CPabBKwA0oHrVHUPQFbnDN7yDmCiiNwHLAzO7ZxzzjlX5Ik1UiW2Zs2a6bx588IOwzkXQyIyX1WbhR3HofLrl3PJJ6frV8IO/nfOOeecK2o8MXPOOeecixOemDnnnHPOxYkiMcZMRLYA3+ThkGrAj4UUTn55TNHxmKIXj3EVZEx1VTXha+X49avQxGNMEJ9xeUzRicn1q0gkZnklIvPibdCwxxQdjyl68RhXPMaUaOLxO/SYohePcXlM0YlVTN6V6ZxzzjkXJzwxc84555yLE8mamD0bdgBZ8Jii4zFFLx7jiseYEk08foceU/TiMS6PKToxiSkpx5g555xzzsWjZG0xc84555yLO0mVmIlIOxFZJSJrRWRw2PEAiEiaiCwVkUUiEtq6LCLyooj8ICLLIrYdJiLvicia4L5KHMQ0XEQ2Bt/XIhG5KMYx1RGRmSKyQkSWi8gNwfbQvqscYgrtuxKR0iIyR0QWBzH9PdheX0RmB7+Dr4hIyVjFlOji8foF8XEN8+tX1DH59Sv6uMK7hqlqUtywxdK/Bo4CSgKLgSZxEFcaUC0O4jgHOAVYFrHtIWBw8Hgw8GAcxDQcuDXE76kmcErwuAKwGmgS5neVQ0yhfVeAAOWDxyWA2UALYBLQM9j+DHBtWP+WiXSL1+tXEFvo1zC/fkUdk1+/oo8rtGtYMrWYNQfWquo6Vd0FTAQ6hxxT3FDVj4GfMm3uDIwNHo8FusRBTKFS1U2quiB4/BuwEqhFiN9VDjGFRs3vwdMSwU2B84DJwfaY/0wlML9+5cCvX9Hx61f0wryGJVNiVgv4NuL5BuLgHx/7h35XROaLyICwg8mkhqpuCh5/D9QIM5gIA0VkSdBVENPuiUgiUg84GftLKi6+q0wxQYjflYikiMgi4AfgPazF52dVTQ92iZffwUQQr9cviN9rWFz8TmbBr1/RxQQhf1dhXcOSKTGLV2ep6ilAe+A6ETkn7ICyotZuGw9TeJ8GGgBNgU3AI2EEISLlgSnAjar6a+RrYX1XWcQU6nelqntUtSlQG2vxOSaW7+9iJu6vYX79OpBfv6IT1jUsmRKzjUCdiOe1g22hUtWNwf0PwOvYP3682CwiNQGC+x9CjgdV3Rz8suwFniOE70tESmAXkJdV9bVgc6jfVVYxxcN3FcTxMzATaAlUFpHiwUtx8TuYIOLy+gVxfQ3z61cW/PqVd7G+hiVTYjYXaBTMqCgJ9ASmhhmQiJQTkQoZj4ELgGU5HxVTU4G+weO+wJshxgLsu2hkuIQYf18iIsALwEpV/WfES6F9V9nFFOZ3JSLVRaRy8LgM0BYbOzIT6BbsFhc/Uwki7q5fEPfXML9+Hfz+fv2KPq7wrmGxmuEQDzfgImzGx9fA0DiI5yhsdtViYHmYMQH/wZqLd2P95v2BqsAHwBrgfeCwOIjpJWApsAS7mNSMcUxnYc38S4BFwe2iML+rHGIK7bsCTgQWBu+9DLg72H4UMAdYC7wKlIrlv18i3+Lt+hXx7xn6NcyvX1HH5Nev6OMK7Rrmlf+dc8455+JEMnVlOuecc87FNU/MnHPOOefihCdmzjnnnHNxwhMz55xzzrk44YmZc84551yc8MTMOeeccy5OeGLmnHPOORcnPDFzzjnnnIsT/w+D3Szeq96FOwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xo3KyjRge1C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7c1217b7-08e3-43a1-8810-fada38f90718"
      },
      "source": [
        "print('plot graph for learning rate changes')\n",
        "x_list = list(range(len(cur_lr_list)))\n",
        "plt.plot(x_list, cur_lr_list,label=\"learning rate plot\")\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "plot graph for learning rate changes\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZf5-O9EzzoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204d3fd0-099b-4200-ebdd-9afe7fb1172f"
      },
      "source": [
        "# assert False\n",
        "assert best_model is not None, \"best model is not assigned correctly on above code\"\n",
        "SAVE_PATH = \"/content/gdrive/MyDrive/Colab_Notebooks/model_Adam.pth\"\n",
        "torch.save(best_model['model'], SAVE_PATH)\n",
        "for k,v in best_model.items():\n",
        "  if k is not 'model':\n",
        "    print(f\"{k}: {v}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best epoch: 16\n",
            "Best Acc on validation set: 0.8439363837242126\n",
            "Best(lowest) validation loss: 0.006838291083605104\n"
          ]
        }
      ]
    }
  ]
}